From ff0d29945f9607cf0d4cd88bb94596703d393425 Mon Sep 17 00:00:00 2001
From: Michael McAuliffe <michael.e.mcauliffe@gmail.com>
Date: Sun, 16 Oct 2022 13:12:32 -0700
Subject: [PATCH] PyKaldi compatibility

---
 src/base/kaldi-error.cc                       |  13 +-
 src/base/kaldi-error.h                        |  28 +-
 src/chain/chain-supervision.h                 |   2 +-
 src/cudamatrix/cu-device.h                    |   2 +
 src/cudamatrix/cu-matrix.cc                   |   8 +-
 src/cudamatrix/cu-matrix.h                    |  11 +-
 src/cudamatrix/cu-vector.cc                   |   3 +-
 src/cudamatrix/cu-vector.h                    |  28 +-
 src/decoder/decodable-matrix.h                |   6 +-
 src/decoder/decoder-wrappers.cc               |  15 +
 src/decoder/grammar-fst.cc                    |   7 +
 src/decoder/grammar-fst.h                     |  31 ++-
 src/decoder/lattice-faster-decoder.cc         |   7 +
 src/decoder/lattice-faster-online-decoder.cc  |   4 +
 src/decoder/lattice-faster-online-decoder.h   |   4 +-
 src/decoder/lattice-incremental-decoder.cc    |   8 +
 .../lattice-incremental-online-decoder.cc     |   3 +
 src/feat/feature-common.h                     |   2 +-
 src/feat/feature-functions.cc                 |   2 +-
 src/feat/feature-functions.h                  |   2 +-
 src/{lat => fstext}/arctic-weight.h           |   8 +-
 src/fstext/deterministic-fst.h                |   2 +-
 src/fstext/lattice-weight.h                   |   4 +-
 src/gmm/am-diag-gmm.h                         |   2 +-
 src/gmm/diag-gmm.h                            |   4 +-
 src/gmm/full-gmm-normal.h                     |   4 +-
 src/gmm/mle-am-diag-gmm.cc                    |   5 +
 src/gmm/mle-am-diag-gmm.h                     |   2 +
 src/hmm/posterior.h                           |   2 +-
 src/hmm/transition-model.h                    |   2 +-
 src/hmm/tree-accu.h                           |   2 +-
 src/ivector/agglomerative-clustering.cc       |   8 +-
 src/ivector/agglomerative-clustering.h        |   8 +-
 src/kws/kaldi-kws.h                           |   2 +-
 src/kws/kws-functions.h                       | 101 +++++++
 src/kws/kws-functions2.cc                     | 239 ++++++++++++++++
 src/kwsbin/kws-index-union.cc                 |  13 +-
 src/kwsbin/kws-search.cc                      | 258 ++++--------------
 src/kwsbin/lattice-to-kws-index.cc            |  88 +-----
 src/lat/determinize-lattice-pruned.cc         |   6 +
 src/lat/word-align-lattice.h                  |   4 +-
 src/matrix/kaldi-matrix.cc                    |  10 +-
 src/matrix/kaldi-matrix.h                     |  19 +-
 src/matrix/kaldi-vector.cc                    |  22 +-
 src/matrix/kaldi-vector.h                     |  35 ++-
 src/matrix/matrix-common.h                    |   8 +-
 src/matrix/packed-matrix.h                    |   3 +-
 src/matrix/sp-matrix.cc                       |   3 +-
 src/matrix/sp-matrix.h                        |   8 +-
 src/matrix/tp-matrix.h                        |   4 +-
 src/nnet3/am-nnet-simple.h                    |   4 +
 src/nnet3/decodable-online-looped.cc          |  18 +-
 src/nnet3/decodable-online-looped.h           |   4 +
 src/nnet3/nnet-analyze.h                      |   1 +
 src/nnet3/nnet-computation-graph.h            |   2 +-
 src/nnet3/nnet-descriptor.h                   |   2 +-
 src/nnet3/nnet-example-utils.h                |   2 +-
 src/nnet3/nnet-optimize.h                     |  10 +-
 src/nnet3/nnet-simple-component.cc            |   2 +-
 src/nnet3/nnet-simple-component.h             |   4 +-
 src/online2/online-endpoint.cc                |  17 ++
 src/online2/online-feature-pipeline.h         |   2 +-
 src/online2/online-gmm-decoding.h             |   2 +-
 src/online2/online-ivector-feature.cc         |  11 +
 src/online2/online-ivector-feature.h          |   4 +-
 src/online2/online-nnet2-feature-pipeline.h   |  14 +-
 src/online2/online-nnet3-decoding.cc          |   1 +
 src/online2/online-nnet3-decoding.h           |   2 +
 src/online2/online-timing.h                   |   2 +-
 src/rnnlm/rnnlm-core-compute.cc               |   4 +-
 src/rnnlm/rnnlm-core-compute.h                |   6 +-
 src/rnnlm/sampling-lm-estimate.h              |   2 +-
 src/rnnlm/sampling-lm.h                       |   2 +-
 src/rnnlmbin/rnnlm-compute-prob.cc            |   2 +-
 src/transform/compressed-transform-stats.h    |   2 +-
 src/transform/fmllr-diag-gmm.h                |  10 +-
 src/tree/build-tree-questions.h               |   2 +-
 src/tree/context-dep.h                        |   2 +
 src/tree/tree-renderer.cc                     |   4 +
 src/tree/tree-renderer.h                      |   4 +
 src/util/kaldi-holder.h                       |   8 +-
 src/util/kaldi-io.cc                          |  10 +
 src/util/kaldi-io.h                           |   7 +-
 src/util/kaldi-table.h                        |  32 +++
 src/util/stl-utils.h                          |  15 +
 85 files changed, 854 insertions(+), 424 deletions(-)
 rename src/{lat => fstext}/arctic-weight.h (97%)

diff --git a/src/base/kaldi-error.cc b/src/base/kaldi-error.cc
index 12f972e..134de54 100644
--- a/src/base/kaldi-error.cc
+++ b/src/base/kaldi-error.cc
@@ -47,6 +47,11 @@ int32 g_kaldi_verbose_level = 0;
 static std::string program_name;
 static LogHandler log_handler = NULL;
 
+/*PyKaldi change*/
+bool g_abort_on_assert_failure = true;
+bool g_print_stack_trace_on_error = true;
+/* /// */
+
 void SetProgramName(const char *basename) {
   // Using the 'static std::string' for the program name is mostly harmless,
   // because (a) Kaldi logging is undefined before main(), and (b) no stdc++
@@ -215,7 +220,8 @@ void MessageLogger::LogMessage() const {
                << envelope_.line << ") " << GetMessage().c_str();
 
   // Add stack trace for errors and assertion failures, if available.
-  if (envelope_.severity < LogMessageEnvelope::kWarning) {
+  if (envelope_.severity < LogMessageEnvelope::kWarning &&
+      g_print_stack_trace_on_error) {
     const std::string &stack_trace = KaldiGetStackTrace();
     if (!stack_trace.empty()) {
       full_message << "\n\n" << stack_trace;
@@ -234,8 +240,11 @@ void KaldiAssertFailure_(const char *func, const char *file, int32 line,
   MessageLogger::Log() =
       MessageLogger(LogMessageEnvelope::kAssertFailed, func, file, line)
       << "Assertion failed: (" << cond_str << ")";
-  fflush(NULL); // Flush all pending buffers, abort() may not flush stderr.
+  if (g_abort_on_assert_failure) {  // PyKaldi change
   std::abort();
+    fflush(NULL); // Flush all pending buffers, abort() may not flush stderr.
+    std::abort();
+  }
 }
 
 /***** THIRD-PARTY LOG-HANDLER *****/
diff --git a/src/base/kaldi-error.h b/src/base/kaldi-error.h
index a9904a7..df3b02c 100644
--- a/src/base/kaldi-error.h
+++ b/src/base/kaldi-error.h
@@ -56,6 +56,17 @@ void SetProgramName(const char *basename);
 /// Do not use directly, prefer {Get,Set}VerboseLevel().
 extern int32 g_kaldi_verbose_level;
 
+/*pykaldi change*/
+/// This is used for enabling/disabling the call to abort in the case of an
+/// assertion failure.
+extern bool g_abort_on_assert_failure;
+
+/// This is used for enabling/disabling the printing of stack trace in the
+/// case of an error.
+extern bool g_print_stack_trace_on_error;
+
+/* / */
+
 /// Get verbosity level, usually set via command line '--verbose=' switch.
 inline int32 GetVerboseLevel() { return g_kaldi_verbose_level; }
 
@@ -63,6 +74,21 @@ inline int32 GetVerboseLevel() { return g_kaldi_verbose_level; }
 /// command-line programs set the verbose level automatically from ParseOptions.
 inline void SetVerboseLevel(int32 i) { g_kaldi_verbose_level = i; }
 
+/*pykaldi change*/
+
+/// This is used by executables to enable/disable the call to abort in the
+/// case of an assertion failure.
+inline void SetAbortOnAssertFailure(bool a) { g_abort_on_assert_failure = a; }
+
+/// This is used by executables to enable/disable the printing of stack trace
+/// in the case of an error.
+inline void SetPrintStackTraceOnError(bool p) {
+  g_print_stack_trace_on_error = p;
+}
+
+
+/* --- */
+
 /***** KALDI LOGGING *****/
 
 /// Log message severity and source location info.
@@ -161,7 +187,7 @@ private:
 
 /***** KALDI ASSERTS *****/
 
-[[noreturn]] void KaldiAssertFailure_(const char *func, const char *file,
+void KaldiAssertFailure_(const char *func, const char *file,
                                       int32 line, const char *cond_str);
 
 // Note on KALDI_ASSERT and KALDI_PARANOID_ASSERT:
diff --git a/src/chain/chain-supervision.h b/src/chain/chain-supervision.h
index f1a796d..d6ab065 100644
--- a/src/chain/chain-supervision.h
+++ b/src/chain/chain-supervision.h
@@ -353,7 +353,7 @@ void SortBreadthFirstSearch(fst::StdVectorFst *fst);
 // multiple pieces corresponding to different frame-ranges.
 class SupervisionSplitter {
  public:
-  SupervisionSplitter(const Supervision &supervision);
+  explicit SupervisionSplitter(const Supervision &supervision);
 
   // Extracts a frame range of the supervision into 'supervision'.  Note: the
   // supervision object should not be used for training before you do
diff --git a/src/cudamatrix/cu-device.h b/src/cudamatrix/cu-device.h
index 2f278eb..b8d76d2 100644
--- a/src/cudamatrix/cu-device.h
+++ b/src/cudamatrix/cu-device.h
@@ -92,6 +92,8 @@ class CuDevice {
       ans.Initialize();
     return ans;
   }
+  
+  static inline CuDevice* InstantiatePtr() { return &Instantiate(); }
 
   cublasHandle_t GetCublasHandle() const { return cublas_handle_; }
   cusparseHandle_t GetCusparseHandle() const { return cusparse_handle_; }
diff --git a/src/cudamatrix/cu-matrix.cc b/src/cudamatrix/cu-matrix.cc
index c67842d..b3d69b1 100644
--- a/src/cudamatrix/cu-matrix.cc
+++ b/src/cudamatrix/cu-matrix.cc
@@ -341,8 +341,9 @@ void CuMatrixBase<Real>::CopyFromMat(const MatrixBase<Real> &src,
 
 template<typename Real>
 template<typename OtherReal>
-void CuMatrixBase<Real>::CopyFromMat(const MatrixBase<OtherReal> &src,
-                                     MatrixTransposeType trans) {
+typename std::enable_if<!std::is_same<OtherReal, Real>::value>::type
+CuMatrixBase<Real>::CopyFromMat(const MatrixBase<OtherReal> &src,
+                                MatrixTransposeType trans) {
   CuMatrix<OtherReal> temp(src);
   this->CopyFromMat(temp, trans);
 }
@@ -3180,7 +3181,8 @@ template void Matrix<double>::Swap(CuMatrix<double> *mat);
 
 /// Copy constructor from another type.
 template<typename Real>
-template<typename OtherReal>
+template<typename OtherReal,
+         typename std::enable_if<!std::is_same<OtherReal, Real>::value>::type*>
 CuMatrix<Real>::CuMatrix(const CuMatrixBase<OtherReal> & M,
                          MatrixTransposeType trans) : CuMatrixBase<Real>() {
 
diff --git a/src/cudamatrix/cu-matrix.h b/src/cudamatrix/cu-matrix.h
index a531ecd..d4f08bb 100644
--- a/src/cudamatrix/cu-matrix.h
+++ b/src/cudamatrix/cu-matrix.h
@@ -235,8 +235,9 @@ class CuMatrixBase {
 
   // Copy functions.  These do not resize.
   template<typename OtherReal>
-  void CopyFromMat(const MatrixBase<OtherReal> &src,
-                   MatrixTransposeType trans = kNoTrans);
+  typename std::enable_if<!std::is_same<OtherReal, Real>::value>::type
+  CopyFromMat(const MatrixBase<OtherReal> &src,
+              MatrixTransposeType trans = kNoTrans);
 
 
   void CopyFromGeneralMat(const GeneralMatrix &src,
@@ -835,7 +836,8 @@ class CuMatrix: public CuMatrixBase<Real> {
   }
 
   /// Copy constructor: as above, but from another type.
-  template<typename OtherReal>
+  template<typename OtherReal,
+           typename std::enable_if<!std::is_same<OtherReal, Real>::value>::type* = nullptr >
   explicit CuMatrix(const CuMatrixBase<OtherReal> &M,
                     MatrixTransposeType trans = kNoTrans);
 
@@ -868,7 +870,8 @@ class CuMatrix: public CuMatrixBase<Real> {
   void Swap(CuMatrix<Real> *mat);
 
   template<typename OtherReal>
-  void Swap(CuMatrix<OtherReal> *mat);
+  typename std::enable_if<!std::is_same<OtherReal, Real>::value>::type
+  Swap(CuMatrix<OtherReal> *mat);
 
   /// I/O functions
   void Read(std::istream &is, bool binary);
diff --git a/src/cudamatrix/cu-vector.cc b/src/cudamatrix/cu-vector.cc
index 8736782..9d7c256 100644
--- a/src/cudamatrix/cu-vector.cc
+++ b/src/cudamatrix/cu-vector.cc
@@ -1258,7 +1258,8 @@ void CuVectorBase<Real>::AddVec(Real alpha, const CuVectorBase<Real> &vec,
 
 template<typename Real>
 template<typename OtherReal>
-void CuVectorBase<Real>::AddVec(Real alpha, const CuVectorBase<OtherReal> &vec,
+typename std::enable_if<!std::is_same<OtherReal, Real>::value>::type
+CuVectorBase<Real>::AddVec(Real alpha, const CuVectorBase<OtherReal> &vec,
                                 Real beta) {
   // We could implement this directly, without using a temporary-- this can
   // be done later, when we have time.
diff --git a/src/cudamatrix/cu-vector.h b/src/cudamatrix/cu-vector.h
index f1c3275..5fe3b2d 100644
--- a/src/cudamatrix/cu-vector.h
+++ b/src/cudamatrix/cu-vector.h
@@ -79,7 +79,8 @@ class CuVectorBase {
   void CopyFromVec(const CuVectorBase<Real> &src);
 
   template<typename OtherReal>
-  void CopyFromVec(const CuVectorBase<OtherReal> &M);
+  typename std::enable_if<!std::is_same<OtherReal, Real>::value>::type
+  CopyFromVec(const CuVectorBase<OtherReal> &M);
 
   template<typename OtherReal>
   void CopyFromVec(const VectorBase<OtherReal> &src);
@@ -98,9 +99,10 @@ class CuVectorBase {
   void Scale(Real value);
 
   void AddVec(Real alpha, const CuVectorBase<Real> &vec, Real beta = 1.0);
-
+  
   template<typename OtherReal>
-  void AddVec(Real alpha, const CuVectorBase<OtherReal> &vec, Real beta = 1.0);
+  typename std::enable_if<!std::is_same<OtherReal, Real>::value>::type
+  AddVec(Real alpha, const CuVectorBase<OtherReal> &vec, Real beta = 1.0);
 
   /// Sum the rows of the matrix, add to vector
   void AddRowSumMat(Real alpha, const CuMatrixBase<Real> &mat, Real beta = 1.0);
@@ -264,23 +266,26 @@ class CuVector: public CuVectorBase<Real> {
 
  public:
   CuVector() { }
-  CuVector(MatrixIndexT dim, MatrixResizeType t = kSetZero) { Resize(dim, t); }
-
-  CuVector(const CuVectorBase<Real> &v);
+  explicit CuVector(MatrixIndexT dim, MatrixResizeType t = kSetZero) { Resize(dim, t); }
 
-  CuVector(const VectorBase<Real> &v);
-  explicit CuVector(const CuVector<Real> &v) : CuVectorBase<Real>() {
+  CuVector(const CuVector<Real> &v) : CuVectorBase<Real>() {
     Resize(v.Dim(), kUndefined);
     this->CopyFromVec(v);
   }
 
-  template<typename OtherReal>
+  explicit CuVector(const CuVectorBase<Real> &v);
+
+  explicit CuVector(const VectorBase<Real> &v);
+
+  template<typename OtherReal,
+           typename std::enable_if<!std::is_same<OtherReal,Real>::value>::type* = nullptr >
   explicit CuVector(const CuVectorBase<OtherReal> &v) : CuVectorBase<Real>() {
     Resize(v.Dim(), kUndefined);
     this->CopyFromVec(v);
   }
 
-  template<typename OtherReal>
+  template<typename OtherReal,
+           typename std::enable_if<!std::is_same<OtherReal,Real>::value>::type* = nullptr >
   explicit CuVector(const VectorBase<OtherReal> &v) : CuVectorBase<Real>() {
     Resize(v.Dim(), kUndefined);
     this->CopyFromVec(Vector<Real>(v));
@@ -374,7 +379,8 @@ inline void AssertEqual(const CuVectorBase<Real> &a,
 
 template<typename Real>
 template<typename OtherReal>
-void CuVectorBase<Real>::CopyFromVec(const CuVectorBase<OtherReal> &v) {
+typename std::enable_if<!std::is_same<OtherReal,Real>::value>::type
+CuVectorBase<Real>::CopyFromVec(const CuVectorBase<OtherReal> &v) {
   v.CopyToVec(&this);
 }
 
diff --git a/src/decoder/decodable-matrix.h b/src/decoder/decodable-matrix.h
index 94e141d..265a66c 100644
--- a/src/decoder/decodable-matrix.h
+++ b/src/decoder/decodable-matrix.h
@@ -47,7 +47,7 @@ class DecodableMatrixScaledMapped: public DecodableInterface {
 
   // This constructor creates an object that will delete "likes"
   // when done.
-  DecodableMatrixScaledMapped(const TransitionInformation &tm,
+  explicit DecodableMatrixScaledMapped(const TransitionInformation &tm,
                               BaseFloat scale,
                               const Matrix<BaseFloat> *likes):
       trans_model_(tm), likes_(likes),
@@ -156,7 +156,7 @@ class DecodableMatrixMapped: public DecodableInterface {
 */
 class DecodableMatrixMappedOffset: public DecodableInterface {
  public:
-  DecodableMatrixMappedOffset(const TransitionInformation &tm):
+  explicit DecodableMatrixMappedOffset(const TransitionInformation &tm):
       trans_model_(tm), tid_to_pdf_(trans_model_.TransitionIdToPdfArray()),
       frame_offset_(0), input_is_finished_(false) { }
 
@@ -219,7 +219,7 @@ class DecodableMatrixMappedOffset: public DecodableInterface {
 
 class DecodableMatrixScaled: public DecodableInterface {
  public:
-  DecodableMatrixScaled(const Matrix<BaseFloat> &likes,
+  explicit DecodableMatrixScaled(const Matrix<BaseFloat> &likes,
                         BaseFloat scale):
     likes_(likes), scale_(scale) { }
 
diff --git a/src/decoder/decoder-wrappers.cc b/src/decoder/decoder-wrappers.cc
index 626a693..70ab7f8 100644
--- a/src/decoder/decoder-wrappers.cc
+++ b/src/decoder/decoder-wrappers.cc
@@ -442,6 +442,21 @@ template bool DecodeUtteranceLatticeFaster(
     LatticeWriter *lattice_writer,
     double *like_ptr);
 
+/*PyKaldi*/
+template bool DecodeUtteranceLatticeFaster(
+    LatticeFasterDecoderTpl<fst::GrammarFst > &decoder,
+    DecodableInterface &decodable,
+    const TransitionModel &trans_model,
+    const fst::SymbolTable *word_syms,
+    std::string utt,
+    double acoustic_scale,
+    bool determinize,
+    bool allow_partial,
+    Int32VectorWriter *alignment_writer,
+    Int32VectorWriter *words_writer,
+    CompactLatticeWriter *compact_lattice_writer,
+    LatticeWriter *lattice_writer,
+    double *like_ptr);
 
 // Takes care of output.  Returns true on success.
 bool DecodeUtteranceLatticeSimple(
diff --git a/src/decoder/grammar-fst.cc b/src/decoder/grammar-fst.cc
index a92be3e..21fe1cc 100644
--- a/src/decoder/grammar-fst.cc
+++ b/src/decoder/grammar-fst.cc
@@ -1040,13 +1040,20 @@ void CopyToVectorFst(GrammarFstTpl<FST> *grammar_fst,
 // Instantiate the template for the instance fst types that are used in kaldi
 template class GrammarFstTpl<const ConstFst<StdArc> >;
 template class GrammarFstTpl<StdVectorFst>;
+/*PyKaldi:*/
+template class GrammarFstTpl<ConstFst<StdArc> >;
 
 template class ArcIterator<GrammarFstTpl<const ConstFst<StdArc> > >;
 template class ArcIterator<GrammarFstTpl<StdVectorFst> >;
+/*PyKaldi:*/
+template class ArcIterator<GrammarFstTpl<ConstFst<StdArc> > >;
 
 // Instantiate the function template for CopyToVectorFST
 template void CopyToVectorFst<const ConstFst<StdArc> >(GrammarFstTpl<const ConstFst<StdArc> > *grammar_fst,
                                                        VectorFst<StdArc> *vector_fst);
 template void CopyToVectorFst<StdVectorFst>(GrammarFstTpl<StdVectorFst> *grammar_fst,
                                                        VectorFst<StdArc> *vector_fst);
+/*PyKaldi:*/
+template void CopyToVectorFst<ConstFst<StdArc> >(GrammarFstTpl<ConstFst<StdArc> > *grammar_fst,
+                                                       VectorFst<StdArc> *vector_fst);
 } // end namespace fst
diff --git a/src/decoder/grammar-fst.h b/src/decoder/grammar-fst.h
index 4d5097d..480deb3 100644
--- a/src/decoder/grammar-fst.h
+++ b/src/decoder/grammar-fst.h
@@ -30,7 +30,7 @@
    OpenFst's Replace() function, but with support for left-biphone context.
  */
 
-
+#include <memory>
 
 #include "fst/fstlib.h"
 #include "fstext/grammar-context-fst.h"
@@ -145,11 +145,39 @@ class GrammarFstTpl {
               than once in 'fsts'.  ifsts may be empty, even though that doesn't
               make much sense.
     */
+
   GrammarFstTpl(
       int32 nonterm_phones_offset,
       std::shared_ptr<FST> top_fst,
       const std::vector<std::pair<int32, std::shared_ptr<FST> > > &ifsts);
 
+ #ifdef __APPLE__
+  /* Benjamin: The above constructure was problematic with PyClif when compiling on Mac, 
+   * but could be linked from PyClif without problems on Linux!
+   * On Mac, there seems to be problems with shared pointers as arguments.
+   * We use make shared to copy top_fst and turn it into a shared pointer<FST>
+   * Fixme: reinterpret_cast for ifsts, doesnt look safe
+   * Note that the argument order is changed to not interfere with the rest of Kaldi */
+  GrammarFstTpl(
+      FST top_fst,
+      const std::vector<std::pair<int32, FST > > &ifsts,
+      int32 nonterm_phones_offset) : 
+  GrammarFstTpl(
+      nonterm_phones_offset,
+      std::make_shared<FST>(top_fst),
+      reinterpret_cast<const std::vector<std::pair<int32, std::shared_ptr<FST> > > &>(ifsts)) {}
+  #else
+  //same argument order for non-apple case
+  GrammarFstTpl(
+      std::shared_ptr<FST> top_fst,
+      const std::vector<std::pair<int32, std::shared_ptr<FST> > > &ifsts,
+      int32 nonterm_phones_offset) :
+  GrammarFstTpl(
+      nonterm_phones_offset,
+      top_fst,
+      ifsts) {}
+  #endif
+
   /// Copy constructor.  Useful because this object is not thread safe so cannot
   /// be used by multiple parallel decoder threads, but it is lightweight and
   /// can copy it without causing the stored FSTs to be copied.
@@ -646,6 +674,7 @@ void PrepareForGrammarFst(int32 nonterm_phones_offset,
 // Template aliases
 using ConstGrammarFst = GrammarFstTpl<const ConstFst<StdArc> >;
 using VectorGrammarFst =  GrammarFstTpl<StdVectorFst>;
+using GrammarFst = GrammarFstTpl<StdConstFst>;
 
 } // end namespace fst
 
diff --git a/src/decoder/lattice-faster-decoder.cc b/src/decoder/lattice-faster-decoder.cc
index 42d1d2a..efbf703 100644
--- a/src/decoder/lattice-faster-decoder.cc
+++ b/src/decoder/lattice-faster-decoder.cc
@@ -1007,12 +1007,19 @@ template class LatticeFasterDecoderTpl<fst::Fst<fst::StdArc>, decoder::StdToken>
 template class LatticeFasterDecoderTpl<fst::VectorFst<fst::StdArc>, decoder::StdToken >;
 template class LatticeFasterDecoderTpl<fst::ConstFst<fst::StdArc>, decoder::StdToken >;
 
+/*pykaldi*/
+template class LatticeFasterDecoderTpl<fst::GrammarFst, decoder::StdToken>;
+
 template class LatticeFasterDecoderTpl<fst::ConstGrammarFst, decoder::StdToken>;
 template class LatticeFasterDecoderTpl<fst::VectorGrammarFst, decoder::StdToken>;
 
 template class LatticeFasterDecoderTpl<fst::Fst<fst::StdArc> , decoder::BackpointerToken>;
 template class LatticeFasterDecoderTpl<fst::VectorFst<fst::StdArc>, decoder::BackpointerToken >;
 template class LatticeFasterDecoderTpl<fst::ConstFst<fst::StdArc>, decoder::BackpointerToken >;
+
+/*pykaldi*/
+template class LatticeFasterDecoderTpl<fst::GrammarFst, decoder::BackpointerToken>;
+
 template class LatticeFasterDecoderTpl<fst::ConstGrammarFst, decoder::BackpointerToken>;
 template class LatticeFasterDecoderTpl<fst::VectorGrammarFst, decoder::BackpointerToken>;
 
diff --git a/src/decoder/lattice-faster-online-decoder.cc b/src/decoder/lattice-faster-online-decoder.cc
index ebdace7..a5e1743 100644
--- a/src/decoder/lattice-faster-online-decoder.cc
+++ b/src/decoder/lattice-faster-online-decoder.cc
@@ -278,6 +278,10 @@ bool LatticeFasterOnlineDecoderTpl<FST>::GetRawLatticePruned(
 template class LatticeFasterOnlineDecoderTpl<fst::Fst<fst::StdArc> >;
 template class LatticeFasterOnlineDecoderTpl<fst::VectorFst<fst::StdArc> >;
 template class LatticeFasterOnlineDecoderTpl<fst::ConstFst<fst::StdArc> >;
+
+/*pykaldi*/
+template class LatticeFasterOnlineDecoderTpl<fst::GrammarFst >;
+
 template class LatticeFasterOnlineDecoderTpl<fst::ConstGrammarFst >;
 template class LatticeFasterOnlineDecoderTpl<fst::VectorGrammarFst >;
 
diff --git a/src/decoder/lattice-faster-online-decoder.h b/src/decoder/lattice-faster-online-decoder.h
index 8b10996..022df07 100644
--- a/src/decoder/lattice-faster-online-decoder.h
+++ b/src/decoder/lattice-faster-online-decoder.h
@@ -135,8 +135,8 @@ class LatticeFasterOnlineDecoderTpl:
   bool GetRawLatticePruned(Lattice *ofst,
                            bool use_final_probs,
                            BaseFloat beam) const;
-
-  KALDI_DISALLOW_COPY_AND_ASSIGN(LatticeFasterOnlineDecoderTpl);
+  protected:
+    KALDI_DISALLOW_COPY_AND_ASSIGN(LatticeFasterOnlineDecoderTpl);
 };
 
 typedef LatticeFasterOnlineDecoderTpl<fst::StdFst> LatticeFasterOnlineDecoder;
diff --git a/src/decoder/lattice-incremental-decoder.cc b/src/decoder/lattice-incremental-decoder.cc
index b022474..235aeaa 100644
--- a/src/decoder/lattice-incremental-decoder.cc
+++ b/src/decoder/lattice-incremental-decoder.cc
@@ -1711,6 +1711,11 @@ template class LatticeIncrementalDecoderTpl<fst::VectorFst<fst::StdArc>,
                                             decoder::StdToken>;
 template class LatticeIncrementalDecoderTpl<fst::ConstFst<fst::StdArc>,
                                             decoder::StdToken>;
+
+/*PyKaldi*/
+template class LatticeIncrementalDecoderTpl<fst::GrammarFst,
+                                            decoder::StdToken>;
+
 template class LatticeIncrementalDecoderTpl<fst::ConstGrammarFst ,
                                             decoder::StdToken>;
 template class LatticeIncrementalDecoderTpl<fst::VectorGrammarFst,
@@ -1726,5 +1731,8 @@ template class LatticeIncrementalDecoderTpl<fst::ConstGrammarFst,
                                             decoder::BackpointerToken>;
 template class LatticeIncrementalDecoderTpl<fst::VectorGrammarFst,
                                             decoder::BackpointerToken>;
+/*pykaldi*/
+template class LatticeIncrementalDecoderTpl<fst::GrammarFst,
+                                            decoder::BackpointerToken>;
 
 } // end namespace kaldi.
diff --git a/src/decoder/lattice-incremental-online-decoder.cc b/src/decoder/lattice-incremental-online-decoder.cc
index cacac2c..a2fc8ef 100644
--- a/src/decoder/lattice-incremental-online-decoder.cc
+++ b/src/decoder/lattice-incremental-online-decoder.cc
@@ -155,4 +155,7 @@ template class LatticeIncrementalOnlineDecoderTpl<fst::ConstFst<fst::StdArc> >;
 template class LatticeIncrementalOnlineDecoderTpl<fst::ConstGrammarFst >;
 template class LatticeIncrementalOnlineDecoderTpl<fst::VectorGrammarFst >;
 
+/*pykaldi*/
+template class LatticeIncrementalOnlineDecoderTpl<fst::GrammarFst >;
+
 } // end namespace kaldi.
diff --git a/src/feat/feature-common.h b/src/feat/feature-common.h
index 3c2fbd3..2860b2a 100644
--- a/src/feat/feature-common.h
+++ b/src/feat/feature-common.h
@@ -114,7 +114,7 @@ class OfflineFeatureTpl {
 
   // Note: feature_window_function_ is the windowing function, which initialized
   // using the options class, that we cache at this level.
-  OfflineFeatureTpl(const Options &opts):
+  explicit OfflineFeatureTpl(const Options &opts):
       computer_(opts),
       feature_window_function_(computer_.GetFrameOptions()) { }
 
diff --git a/src/feat/feature-functions.cc b/src/feat/feature-functions.cc
index 76500cc..955b2dc 100644
--- a/src/feat/feature-functions.cc
+++ b/src/feat/feature-functions.cc
@@ -128,7 +128,7 @@ ShiftedDeltaFeatures::ShiftedDeltaFeatures(
 
 void ShiftedDeltaFeatures::Process(const MatrixBase<BaseFloat> &input_feats,
                             int32 frame,
-                            SubVector<BaseFloat> *output_frame) const {
+                            VectorBase<BaseFloat> *output_frame) const {
   KALDI_ASSERT(frame < input_feats.NumRows());
   int32 num_frames = input_feats.NumRows(),
       feat_dim = input_feats.NumCols();
diff --git a/src/feat/feature-functions.h b/src/feat/feature-functions.h
index 52454f3..ec74996 100644
--- a/src/feat/feature-functions.h
+++ b/src/feat/feature-functions.h
@@ -109,7 +109,7 @@ class ShiftedDeltaFeatures {
 
   void Process(const MatrixBase<BaseFloat> &input_feats,
                int32 frame,
-               SubVector<BaseFloat> *output_frame) const;
+               VectorBase<BaseFloat> *output_frame) const;
  private:
   ShiftedDeltaFeaturesOptions opts_;
   Vector<BaseFloat> scales_;  // a scaling window for each
diff --git a/src/lat/arctic-weight.h b/src/fstext/arctic-weight.h
similarity index 97%
rename from src/lat/arctic-weight.h
rename to src/fstext/arctic-weight.h
index 5c0c6d3..8abbcdd 100644
--- a/src/lat/arctic-weight.h
+++ b/src/fstext/arctic-weight.h
@@ -1,4 +1,4 @@
-// lat/arctic-weight.h
+// fstext/arctic-weight.h
 
 // Copyright 2012  Johns Hopkins University (Author: Guoguo Chen)
 
@@ -18,8 +18,8 @@
 // limitations under the License.
 
 
-#ifndef KALDI_LAT_ARCTIC_WEIGHT_H_
-#define KALDI_LAT_ARCTIC_WEIGHT_H_
+#ifndef KALDI_FSTEXT_ARCTIC_WEIGHT_H_
+#define KALDI_FSTEXT_ARCTIC_WEIGHT_H_
 
 #include "fst/float-weight.h"
 
@@ -150,4 +150,4 @@ inline ArcticWeightTpl<double> Divide(const ArcticWeightTpl<double> &w1,
 
 } // namespace fst
 
-#endif  // KALDI_LAT_ARCTIC_WEIGHT_H_
+#endif  // KALDI_FSTEXT_ARCTIC_WEIGHT_H_
diff --git a/src/fstext/deterministic-fst.h b/src/fstext/deterministic-fst.h
index 5dc6167..0ff84fb 100644
--- a/src/fstext/deterministic-fst.h
+++ b/src/fstext/deterministic-fst.h
@@ -176,7 +176,7 @@ class UnweightedNgramFst: public DeterministicOnDemandFst<Arc> {
   typedef typename Arc::StateId StateId;
   typedef typename Arc::Label Label;
 
-  UnweightedNgramFst(int n);
+  explicit UnweightedNgramFst(int n);
 
   StateId Start() { return start_state_; };
 
diff --git a/src/fstext/lattice-weight.h b/src/fstext/lattice-weight.h
index 7637c4d..aba27e2 100644
--- a/src/fstext/lattice-weight.h
+++ b/src/fstext/lattice-weight.h
@@ -21,7 +21,9 @@
 #ifndef KALDI_FSTEXT_LATTICE_WEIGHT_H_
 #define KALDI_FSTEXT_LATTICE_WEIGHT_H_
 
-#include "fst/fstlib.h"
+#include "fst/float-weight.h"
+#include "fst/string-weight.h"
+#include "fst/pair-weight.h"
 #include "base/kaldi-common.h"
 
 namespace fst {
diff --git a/src/gmm/am-diag-gmm.h b/src/gmm/am-diag-gmm.h
index 20dff82..4e846ec 100644
--- a/src/gmm/am-diag-gmm.h
+++ b/src/gmm/am-diag-gmm.h
@@ -101,7 +101,7 @@ class AmDiagGmm {
 
   void RemovePdf(int32 pdf_index);
 
-  KALDI_DISALLOW_COPY_AND_ASSIGN(AmDiagGmm);
+  // KALDI_DISALLOW_COPY_AND_ASSIGN(AmDiagGmm);
 };
 
 
diff --git a/src/gmm/diag-gmm.h b/src/gmm/diag-gmm.h
index 7aefc93..1d5a5c3 100644
--- a/src/gmm/diag-gmm.h
+++ b/src/gmm/diag-gmm.h
@@ -47,7 +47,7 @@ class DiagGmm {
   /// Empty constructor.
   DiagGmm() : valid_gconsts_(false) { }
 
-  explicit DiagGmm(const DiagGmm &gmm): valid_gconsts_(false) {
+  DiagGmm(const DiagGmm &gmm): valid_gconsts_(false) {
     CopyFromDiagGmm(gmm);
   }
 
@@ -244,8 +244,6 @@ class DiagGmm {
                                      const VectorBase<BaseFloat> &s1,
                                      const VectorBase<BaseFloat> &s2) const;
 
- private:
-  const DiagGmm &operator=(const DiagGmm &other);  // Disallow assignment
 };
 
 /// ostream operator that calls DiagGMM::Write()
diff --git a/src/gmm/full-gmm-normal.h b/src/gmm/full-gmm-normal.h
index 864ddb7..379ee86 100644
--- a/src/gmm/full-gmm-normal.h
+++ b/src/gmm/full-gmm-normal.h
@@ -67,7 +67,9 @@ class FullGmmNormal {
   Matrix<double> means_;                ///< Means
   std::vector<SpMatrix<double> > vars_;  ///< covariances
 
-  KALDI_DISALLOW_COPY_AND_ASSIGN(FullGmmNormal);
+  // KALDI_DISALLOW_COPY_AND_ASSIGN(FullGmmNormal);
+ private:
+  const FullGmmNormal &operator=(const FullGmmNormal &other);  // Disallow assignment.
 };
 
 }  // End namespace kaldi
diff --git a/src/gmm/mle-am-diag-gmm.cc b/src/gmm/mle-am-diag-gmm.cc
index e578d7c..26020cb 100644
--- a/src/gmm/mle-am-diag-gmm.cc
+++ b/src/gmm/mle-am-diag-gmm.cc
@@ -34,6 +34,11 @@ AccumDiagGmm& AccumAmDiagGmm::GetAcc(int32 index) {
   return *(gmm_accumulators_[index]);
 }
 
+AccumDiagGmm* AccumAmDiagGmm::GetAccPtr(int32 index) {
+  KALDI_ASSERT(index >= 0 && index < static_cast<int32>(gmm_accumulators_.size()));
+  return gmm_accumulators_[index];
+}
+
 AccumAmDiagGmm::~AccumAmDiagGmm() {
   DeletePointers(&gmm_accumulators_);
 }
diff --git a/src/gmm/mle-am-diag-gmm.h b/src/gmm/mle-am-diag-gmm.h
index abc8428..4d2146f 100644
--- a/src/gmm/mle-am-diag-gmm.h
+++ b/src/gmm/mle-am-diag-gmm.h
@@ -87,6 +87,8 @@ class AccumAmDiagGmm {
 
   AccumDiagGmm& GetAcc(int32 index);
 
+  AccumDiagGmm* GetAccPtr(int32 index);
+  
   void Add(BaseFloat scale, const AccumAmDiagGmm &other);
 
   void Scale(BaseFloat scale);
diff --git a/src/hmm/posterior.h b/src/hmm/posterior.h
index e153c24..838df5d 100644
--- a/src/hmm/posterior.h
+++ b/src/hmm/posterior.h
@@ -116,7 +116,7 @@ class GaussPostHolder {
   // reading.
   static bool IsReadInBinary() { return true; }
 
-  const T &Value() const { return t_; }
+  T &Value() { return t_; }
 
   void Swap(GaussPostHolder *other) {
     t_.swap(other->t_);
diff --git a/src/hmm/transition-model.h b/src/hmm/transition-model.h
index 60fabb0..bed292f 100644
--- a/src/hmm/transition-model.h
+++ b/src/hmm/transition-model.h
@@ -322,7 +322,7 @@ class TransitionModel: public TransitionInformation {
   /// of pdfs).
   int32 num_pdfs_;
 
-  KALDI_DISALLOW_COPY_AND_ASSIGN(TransitionModel);
+  // KALDI_DISALLOW_COPY_AND_ASSIGN(TransitionModel);
 };
 
 inline int32 TransitionModel::TransitionIdToPdfFast(int32 trans_id) const {
diff --git a/src/hmm/tree-accu.h b/src/hmm/tree-accu.h
index 92e83c5..8e3a47c 100644
--- a/src/hmm/tree-accu.h
+++ b/src/hmm/tree-accu.h
@@ -67,7 +67,7 @@ struct AccumulateTreeStatsInfo {
   std::vector<int32> phone_map;  // if nonempty, maps old phones to new phones.
   int32 context_width;
   int32 central_position;
-  AccumulateTreeStatsInfo(const AccumulateTreeStatsOptions &opts);
+  explicit AccumulateTreeStatsInfo(const AccumulateTreeStatsOptions &opts);
 };
 
 /// Accumulates the stats needed for training context-dependency trees (in the
diff --git a/src/ivector/agglomerative-clustering.cc b/src/ivector/agglomerative-clustering.cc
index ced912e..87d41b9 100644
--- a/src/ivector/agglomerative-clustering.cc
+++ b/src/ivector/agglomerative-clustering.cc
@@ -24,7 +24,8 @@
 
 namespace kaldi {
 
-void AgglomerativeClusterer::Cluster() {
+void AgglomerativeClusterer::Cluster(std::vector<int32> *assignments) {
+  assignments_ = assignments;
   if (num_points_ > first_pass_max_points_)
     ClusterTwoPass();
   else
@@ -230,9 +231,8 @@ void AgglomerativeCluster(
   KALDI_ASSERT(min_clusters >= 0);
   KALDI_ASSERT(max_cluster_fraction >= 1.0 / min_clusters);
   AgglomerativeClusterer ac(costs, threshold, min_clusters,
-                            first_pass_max_points, max_cluster_fraction,
-                            assignments_out);
-  ac.Cluster();
+                            first_pass_max_points, max_cluster_fraction);
+  ac.Cluster(assignments_out);
 }
 
 }  // end namespace kaldi.
diff --git a/src/ivector/agglomerative-clustering.h b/src/ivector/agglomerative-clustering.h
index ffd63a8..3d1946b 100644
--- a/src/ivector/agglomerative-clustering.h
+++ b/src/ivector/agglomerative-clustering.h
@@ -59,11 +59,9 @@ class AgglomerativeClusterer {
       BaseFloat threshold,
       int32 min_clusters,
       int32 first_pass_max_points,
-      BaseFloat max_cluster_fraction,
-      std::vector<int32> *assignments_out)
+      BaseFloat max_cluster_fraction)
       : costs_(costs), threshold_(threshold), min_clusters_(min_clusters),
-        first_pass_max_points_(first_pass_max_points),
-        assignments_(assignments_out) {
+        first_pass_max_points_(first_pass_max_points) {
     num_points_ = costs.NumRows();
 
     // The max_cluster_size_ is a hard limit on the number points in a cluster.
@@ -85,7 +83,7 @@ class AgglomerativeClusterer {
   }
 
   // Clusters points. Chooses single pass or two pass algorithm.
-  void Cluster();
+  void Cluster(std::vector<int32> *assignments);
 
   // Clusters points using single pass algorithm.
   void ClusterSinglePass();
diff --git a/src/kws/kaldi-kws.h b/src/kws/kaldi-kws.h
index dd00348..bd21e43 100644
--- a/src/kws/kaldi-kws.h
+++ b/src/kws/kaldi-kws.h
@@ -22,7 +22,7 @@
 #define KALDI_KWS_KALDI_KWS_H_
 
 #include "fst/fstlib.h"
-#include "lat/arctic-weight.h"
+#include "fstext/arctic-weight.h"
 
 namespace kaldi {
 
diff --git a/src/kws/kws-functions.h b/src/kws/kws-functions.h
index 1558285..cef0466 100644
--- a/src/kws/kws-functions.h
+++ b/src/kws/kws-functions.h
@@ -22,7 +22,9 @@
 #define KALDI_KWS_KWS_FUNCTIONS_H_
 
 #include <vector>
+#include <tuple>
 
+#include "fst/encode.h"
 #include "lat/kaldi-lattice.h"
 #include "kws/kaldi-kws.h"
 
@@ -143,7 +145,106 @@ class KwsProductFstToKwsLexicographicFstMapper {
   uint64 Properties(uint64 props) const { return props; }
 };
 
+// This is the normal version of LatticeToKwsIndex which does not modify input
+// lattice. Creates an inverted KWS index of the given lattice. The output KWS
+// index is over the KwsLexicographicWeight semiring (a triplet of tropical
+// weights with lexicographic ordering). Input lattice should be topologically
+// sorted. max_silence_frames (if non-negative) determines the duration of the
+// longest silence (epsilon) arcs allowed in the output. silence arcs longer
+// than max_silence_frames will be removed. max_states (if positive) determines
+// the maximum number of states allowed in the output. allow_partial determines
+// whether to allow partial output or skip determinization if determinization
+// fails. For details of the algorithm, see: Dogan Can and Murat Saraclar, 2011,
+// "Lattice Indexing for Spoken Term Detection".
+bool LatticeToKwsIndex(const CompactLattice &clat,
+                       int32 utterance_id,
+                       int32 max_silence_frames,
+                       int32 max_states,
+                       bool allow_partial,
+                       KwsLexicographicFst *index_transducer);
+
+// This is the destructive version of LatticeToKwsIndex which modifies input
+// lattice.
+bool LatticeToKwsIndexDestructive(CompactLattice *clat,
+                                  int32 utterance_id,
+                                  int32 max_silence_frames,
+                                  int32 max_states,
+                                  bool allow_partial,
+                                  KwsLexicographicFst *index_transducer);
+
+// Optimizes KWS index by doing encoded epsilon removal, determinization and
+// minimization. max_states (if positive) determines the maximum number of
+// states allowed in the output.
+void OptimizeKwsIndex(KwsLexicographicFst *index, int32 max_states = -1);
+
+// Encode labels on final arcs. Replace output labels of final arcs (utterance
+// ids) with the encoded labels. Replace input labels of final arcs
+// (disambiguation symbols) with epsilons.
+void EncodeKwsDisambiguationSymbols(
+    KwsLexicographicFst *index,
+    fst::internal::EncodeTable<KwsLexicographicArc> *encode_table);
+
+// this is a mapper adapter that helps converting
+// between the StdArc FST (i.e. tropical semiring FST)
+// to the KwsLexicographic FST. Structure will be kept,
+// the weights converted/recomputed
+class VectorFstToKwsLexicographicFstMapper {
+ public:
+  typedef fst::StdArc FromArc;
+  typedef FromArc::Weight FromWeight;
+  typedef KwsLexicographicArc ToArc;
+  typedef KwsLexicographicWeight ToWeight;
+
+  VectorFstToKwsLexicographicFstMapper() {}
+
+  ToArc operator()(const FromArc &arc) const {
+    return ToArc(arc.ilabel,
+                 arc.olabel,
+                 (arc.weight == FromWeight::Zero() ?
+                  ToWeight::Zero() :
+                  ToWeight(arc.weight.Value(),
+                           StdLStdWeight::One())),
+                 arc.nextstate);
+  }
+
+  fst::MapFinalAction FinalAction() const {
+    return fst::MAP_NO_SUPERFINAL;
+  }
+
+  fst::MapSymbolsAction InputSymbolsAction() const {
+    return fst::MAP_COPY_SYMBOLS;
+  }
+
+  fst::MapSymbolsAction OutputSymbolsAction() const {
+    return fst::MAP_COPY_SYMBOLS;
+  }
+
+  uint64 Properties(uint64 props) const { return props; }
+};
 
+// Searches given keyword (FST) inside the KWS index (FST). Returns the n_best
+// results found. Each result is a tuple of (utt_id, time_beg, time_end, score).
+// The encode_table is used for decoding output labels into utterance ids. If
+// matched_seq is non-null, it is set to the result of composition with the
+// index.
+bool SearchKwsIndex(
+    const KwsLexicographicFst &index,
+    const fst::StdVectorFst &keyword,
+    const fst::internal::EncodeTable<KwsLexicographicArc> &encode_table,
+    int32 n_best,
+    std::vector<std::tuple<int32, int32, int32, double>> *results,
+    KwsLexicographicFst *matched_seq = NULL);
+
+// Computes detailed statistics about the individual index matches.
+// Since keyword is an FST, there can be multiple matching paths in the keyword
+// and the index in a given time period. The stats output will provide the
+// results for all matching paths each with the appropriate score. The ilabels
+// output will provide the input labels on those paths.
+void ComputeDetailedStatistics(
+    const KwsLexicographicFst &keyword,
+    const fst::internal::EncodeTable<KwsLexicographicArc> &encode_table,
+    std::vector<std::tuple<int32, int32, int32, double> > *stats,
+    std::vector<std::vector<KwsLexicographicArc::Label> > *ilabels);
 
 } // namespace kaldi
 
diff --git a/src/kws/kws-functions2.cc b/src/kws/kws-functions2.cc
index 71f5583..f96a565 100644
--- a/src/kws/kws-functions2.cc
+++ b/src/kws/kws-functions2.cc
@@ -137,4 +137,243 @@ void OptimizeFactorTransducer(KwsLexicographicFst *index_transducer,
   Decode(index_transducer, encoder);
 }
 
+                       int32 utterance_id,
+                       int32 max_silence_frames,
+                       int32 max_states,
+                       bool allow_partial,
+                       KwsLexicographicFst *index_transducer) {
+    CompactLattice temp(clat);
+    return LatticeToKwsIndexDestructive(&temp, utterance_id, max_silence_frames,
+                                        max_states, allow_partial,
+                                        index_transducer);
+}
+
+bool LatticeToKwsIndexDestructive(CompactLattice *clat,
+                                  int32 utterance_id,
+                                  int32 max_silence_frames,
+                                  int32 max_states,
+                                  bool allow_partial,
+                                  KwsLexicographicFst *index_transducer) {
+  // Get the alignments
+  std::vector<int32> state_times;
+  CompactLatticeStateTimes(*clat, &state_times);
+
+  // Cluster the arcs in the CompactLattice, write the cluster_id on the
+  // output label side.
+  // ClusterLattice() corresponds to the second part of the preprocessing in
+  // Can and Saraclar's paper -- clustering. Note that we do the first part
+  // of preprocessing (the weight pushing step) later when generating the
+  // factor transducer.
+  KALDI_VLOG(1) << "Arc clustering...";
+  if (!ClusterLattice(clat, state_times)) {
+    KALDI_WARN << "State id's and alignments do not match";
+    return false;
+  }
+
+  // The next part is something new, not in the Can and Saraclar paper.  It is
+  // necessary because we have epsilon arcs, due to silences, in our
+  // lattices.  We modify the factor transducer, while maintaining
+  // equivalence, to ensure that states don't have both epsilon *and*
+  // non-epsilon arcs entering them.  (and the same, with "entering"
+  // replaced with "leaving").  Later we will find out which states have
+  // non-epsilon arcs leaving/entering them and use it to be more selective
+  // in adding arcs to connect them with the initial/final states.  The goal
+  // here is to disallow silences at the beginning or ending of a keyword
+  // occurrence.
+  if (true) {
+    EnsureEpsilonProperty(clat);
+    fst::TopSort(clat);
+    // We have to recompute the state times because they will have changed.
+    CompactLatticeStateTimes(*clat, &state_times);
+  }
+
+  // Generate factor transducer
+  // CreateFactorTransducer() corresponds to the "Factor Generation" part of
+  // Can and Saraclar's paper. But we also move the weight pushing step to
+  // this function as we have to compute the alphas and betas anyway.
+  KALDI_VLOG(1) << "Generating factor transducer...";
+  KwsProductFst factor_transducer;
+  if (!CreateFactorTransducer(*clat, state_times, utterance_id,
+                              &factor_transducer)) {
+    KALDI_WARN << "Cannot generate factor transducer";
+    return false;
+  }
+
+  MaybeDoSanityCheck(factor_transducer);
+
+  // Remove long silence arc
+  // We add the filtering step in our implementation. This is because gap
+  // between two successive words in a query term should be less than 0.5s
+  if (max_silence_frames >= 0) {
+    KALDI_VLOG(1) << "Removing long silence...";
+    RemoveLongSilences(max_silence_frames, state_times, &factor_transducer);
+    MaybeDoSanityCheck(factor_transducer);
+  }
+
+  // Do factor merging, and return a transducer in T*T*T semiring. This step
+  // corresponds to the "Factor Merging" part in Can and Saraclar's paper.
+  KALDI_VLOG(1) << "Merging factors...";
+  DoFactorMerging(&factor_transducer, index_transducer);
+
+  MaybeDoSanityCheck(*index_transducer);
+
+  // Do factor disambiguation. It corresponds to the "Factor Disambiguation"
+  // step in Can and Saraclar's paper.
+  KALDI_VLOG(1) << "Doing factor disambiguation...";
+  DoFactorDisambiguation(index_transducer);
+
+  MaybeDoSanityCheck(*index_transducer);
+
+  // Optimize the above factor transducer. It corresponds to the
+  // "Optimization" step in the paper.
+  KALDI_VLOG(1) << "Optimizing factor transducer...";
+  OptimizeFactorTransducer(index_transducer, max_states, allow_partial);
+
+  MaybeDoSanityCheck(*index_transducer);
+
+  return true;
+}
+
+void OptimizeKwsIndex(KwsLexicographicFst *index, int32 max_states) {
+  using namespace fst;
+  KwsLexicographicFst ifst = *index;
+  EncodeMapper<KwsLexicographicArc> encoder(kEncodeLabels, ENCODE);
+  Encode(&ifst, &encoder);
+  try {
+    DeterminizeStar(ifst, index, kDelta, NULL, max_states);
+  } catch(const std::exception &e) {
+    KALDI_WARN << e.what()
+               << " (should affect speed of search but not results)";
+    *index = ifst;
+  }
+  Minimize(index, static_cast<KwsLexicographicFst*>(NULL), kDelta, true);
+  Decode(index, encoder);
+}
+
+void EncodeKwsDisambiguationSymbols(
+    KwsLexicographicFst *index,
+    fst::internal::EncodeTable<KwsLexicographicArc> *encode_table) {
+  using namespace fst;
+  for (StateIterator<KwsLexicographicFst> siter(*index);
+                                         !siter.Done(); siter.Next()) {
+    for (MutableArcIterator<KwsLexicographicFst>
+         aiter(index, siter.Value()); !aiter.Done(); aiter.Next()) {
+      KwsLexicographicArc arc = aiter.Value();
+      // Skip the non-final arcs
+      if (index->Final(arc.nextstate) == KwsLexicographicWeight::Zero())
+        continue;
+      // Encode the input and output label of the final arc, and this is the
+      // new output label for this arc; set the input label to <epsilon>
+      arc.olabel = encode_table->Encode(arc);
+      arc.ilabel = 0;
+      aiter.SetValue(arc);
+    }
+  }
+  ArcSort(index, ILabelCompare<KwsLexicographicArc>());
+}
+
+bool SearchKwsIndex(const KwsLexicographicFst &index,
+                    const fst::StdVectorFst &keyword,
+                    const fst::internal::EncodeTable<KwsLexicographicArc> &encode_table,
+                    int32 n_best,
+                    std::vector<std::tuple<int32, int32, int32, double>> *results,
+                    KwsLexicographicFst *matched_seq) {
+  using namespace fst;
+  KwsLexicographicFst keyword_fst;
+  KwsLexicographicFst result_fst;
+  Map(keyword, &keyword_fst, VectorFstToKwsLexicographicFstMapper());
+  Compose(keyword_fst, index, &result_fst);
+
+  if (matched_seq != NULL) {
+    *matched_seq = result_fst;
+  }
+
+  Project(&result_fst, PROJECT_OUTPUT);
+  Minimize(&result_fst, (KwsLexicographicFst *) nullptr, kDelta, true);
+  ShortestPath(result_fst, &result_fst, n_best);
+  RmEpsilon(&result_fst);
+
+  // No result found
+  if (result_fst.Start() == kNoStateId)
+    return true;
+
+  // Got something here
+  for (ArcIterator<KwsLexicographicFst>
+       aiter(result_fst, result_fst.Start()); !aiter.Done(); aiter.Next()) {
+    const KwsLexicographicArc &arc = aiter.Value();
+
+    // We're expecting a two-state FST
+    if (result_fst.Final(arc.nextstate) != KwsLexicographicWeight::One()) {
+      KALDI_WARN << "The result FST does not have the expected structure";
+      return false;
+    }
+    int32 uid = encode_table.Decode(arc.olabel)->olabel;
+    int32 tbeg = arc.weight.Value2().Value1().Value();
+    int32 tend = arc.weight.Value2().Value2().Value();
+    double score = arc.weight.Value1().Value();
+
+    results->push_back(std::make_tuple(uid, tbeg, tend, score));
+  }
+  return true;
+}
+
+struct ActivePath {
+  std::vector<KwsLexicographicArc::Label> path;
+  KwsLexicographicArc::Weight weight;
+  KwsLexicographicArc::Label last;
+};
+
+static bool GenerateActivePaths(const KwsLexicographicFst &proxy,
+                                std::vector<ActivePath> *paths,
+                                KwsLexicographicFst::StateId cur_state,
+                                std::vector<KwsLexicographicArc::Label> cur_path,
+                                KwsLexicographicWeight cur_weight) {
+  for (fst::ArcIterator<KwsLexicographicFst> aiter(proxy, cur_state);
+       !aiter.Done(); aiter.Next()) {
+    const KwsLexicographicArc &arc = aiter.Value();
+    KwsLexicographicWeight temp_weight = Times(arc.weight, cur_weight);
+
+    cur_path.push_back(arc.ilabel);
+
+    if ( arc.olabel != 0 ) {
+      ActivePath path;
+      path.path = cur_path;
+      path.weight = temp_weight;
+      path.last = arc.olabel;
+      paths->push_back(path);
+    } else {
+      GenerateActivePaths(proxy, paths,
+                          arc.nextstate, cur_path, temp_weight);
+    }
+    cur_path.pop_back();
+  }
+
+  return true;
+}
+
+void ComputeDetailedStatistics(
+    const KwsLexicographicFst &keyword,
+    const fst::internal::EncodeTable<KwsLexicographicArc> &encode_table,
+    std::vector<std::tuple<int32, int32, int32, double> > *stats,
+    std::vector<std::vector<KwsLexicographicArc::Label> > *ilabels) {
+  std::vector<ActivePath> paths;
+
+  if (keyword.Start() == fst::kNoStateId)
+    return;
+
+  GenerateActivePaths(keyword, &paths, keyword.Start(),
+                      std::vector<KwsLexicographicArc::Label>(),
+                      KwsLexicographicWeight::One());
+
+  for (int i = 0; i < paths.size(); ++i) {
+    int32 uid = encode_table.Decode(paths[i].last)->olabel;
+    int32 tbeg = paths[i].weight.Value2().Value1().Value();
+    int32 tend = paths[i].weight.Value2().Value2().Value();
+    double score = paths[i].weight.Value1().Value();
+
+    stats->push_back(std::make_tuple(uid, tbeg, tend, score));
+    ilabels->push_back(paths[i].path);
+  }
+}
+
 } // end namespace kaldi
diff --git a/src/kwsbin/kws-index-union.cc b/src/kwsbin/kws-index-union.cc
index cd82ede..fc27fe0 100644
--- a/src/kwsbin/kws-index-union.cc
+++ b/src/kwsbin/kws-index-union.cc
@@ -82,18 +82,7 @@ int main(int argc, char *argv[]) {
 
     if (skip_opt == false) {
       // Do the encoded epsilon removal, determinization and minimization
-      KwsLexicographicFst ifst = global_index;
-      EncodeMapper<KwsLexicographicArc> encoder(kEncodeLabels, ENCODE);
-      Encode(&ifst, &encoder);
-      try {
-        DeterminizeStar(ifst, &global_index, kDelta, NULL, max_states);
-      } catch(const std::exception &e) {
-        KALDI_WARN << e.what()
-                   << " (should affect speed of search but not results)";
-        global_index = ifst;
-      }
-      Minimize(&global_index, static_cast<KwsLexicographicFst*>(NULL), kDelta, true);
-      Decode(&global_index, encoder);
+      OptimizeKwsIndex(&global_index, max_states);
     } else {
       KALDI_LOG << "Skipping index optimization...";
     }
diff --git a/src/kwsbin/kws-search.cc b/src/kwsbin/kws-search.cc
index 8e2b2a8..4a28271 100644
--- a/src/kwsbin/kws-search.cc
+++ b/src/kwsbin/kws-search.cc
@@ -25,132 +25,39 @@
 #include "fstext/kaldi-fst-io.h"
 #include "kws/kaldi-kws.h"
 
-namespace kaldi {
-
-typedef KwsLexicographicArc Arc;
-typedef Arc::Weight Weight;
-typedef Arc::StateId StateId;
-
-// encode ilabel, olabel pair as a single 64bit (output) symbol
-uint64 EncodeLabel(StateId ilabel, StateId olabel) {
-  return (static_cast<int64>(olabel) << 32) + static_cast<int64>(ilabel);
-}
-
-// extract the osymbol from the 64bit symbol. That represents the utterance id
-// in this setup -- we throw away the isymbol which is typically 0 or an
-// disambiguation symbol
-StateId DecodeLabelUid(uint64 osymbol) {
-  return static_cast<StateId>(osymbol >> 32);
-}
-
-// this is a mapper adapter that helps converting
-// between the StdArc FST (i.e. tropical semiring FST)
-// to the KwsLexicographic FST. Structure will be kept,
-// the weights converted/recomputed
-class VectorFstToKwsLexicographicFstMapper {
- public:
-  typedef fst::StdArc FromArc;
-  typedef FromArc::Weight FromWeight;
-  typedef KwsLexicographicArc ToArc;
-  typedef KwsLexicographicWeight ToWeight;
-
-  VectorFstToKwsLexicographicFstMapper() {}
-
-  ToArc operator()(const FromArc &arc) const {
-    return ToArc(arc.ilabel,
-                 arc.olabel,
-                 (arc.weight == FromWeight::Zero() ?
-                  ToWeight::Zero() :
-                  ToWeight(arc.weight.Value(),
-                           StdLStdWeight::One())),
-                 arc.nextstate);
-  }
-
-  fst::MapFinalAction FinalAction() const {
-    return fst::MAP_NO_SUPERFINAL;
+#include "kws/kws-functions.h"
+
+void WriteKWSResults(
+    const std::string &kwid,
+    const std::vector<std::tuple<kaldi::int32, kaldi::int32, kaldi::int32, double> > &results,
+    const std::vector<std::vector<kaldi::int32> > *paths,
+    int32 frame_subsampling_factor,
+    double negative_tolerance,
+    kaldi::TableWriter<kaldi::BasicVectorHolder<double> > *writer) {
+  if (paths != nullptr) {
+    KALDI_ASSERT(results.size() == (*paths).size());
   }
 
-  fst::MapSymbolsAction InputSymbolsAction() const {
-    return fst::MAP_COPY_SYMBOLS;
-  }
-
-  fst::MapSymbolsAction OutputSymbolsAction() const {
-    return fst::MAP_COPY_SYMBOLS;
-  }
-
-  uint64 Properties(uint64 props) const { return props; }
-};
-
-struct ActivePath {
-  std::vector<KwsLexicographicArc::Label> path;
-  KwsLexicographicArc::Weight weight;
-  KwsLexicographicArc::Label last;
-};
-
-bool GenerateActivePaths(const KwsLexicographicFst &proxy,
-                       std::vector<ActivePath> *paths,
-                       KwsLexicographicFst::StateId cur_state,
-                       std::vector<KwsLexicographicArc::Label> cur_path,
-                       KwsLexicographicArc::Weight cur_weight) {
-  for (fst::ArcIterator<KwsLexicographicFst> aiter(proxy, cur_state);
-       !aiter.Done(); aiter.Next()) {
-    const Arc &arc = aiter.Value();
-    Weight temp_weight = Times(arc.weight, cur_weight);
-
-    cur_path.push_back(arc.ilabel);
-
-    if ( arc.olabel != 0 ) {
-      ActivePath path;
-      path.path = cur_path;
-      path.weight = temp_weight;
-      path.last = arc.olabel;
-      paths->push_back(path);
-    } else {
-      GenerateActivePaths(proxy, paths,
-                        arc.nextstate, cur_path, temp_weight);
+  kaldi::int32 uid, tbeg, tend;
+  double score;
+  for (int i = 0; i < results.size(); ++i) {
+    std::tie(uid, tbeg, tend, score) = results[i];
+    std::vector<double> output;
+    output.push_back(uid);
+    output.push_back(tbeg * frame_subsampling_factor);
+    output.push_back(tend * frame_subsampling_factor);
+    if (score < 0) {
+      if (score < negative_tolerance) {
+        KALDI_WARN << "Score out of expected range: " << score;
+      }
+      score = 0.0;
     }
-    cur_path.pop_back();
-  }
-
-  return true;
-}
-}  // namespace kaldi
-
-typedef kaldi::TableWriter< kaldi::BasicVectorHolder<double> >
-                                                        VectorOfDoublesWriter;
-void OutputDetailedStatistics(const std::string &kwid,
-                        const kaldi::KwsLexicographicFst &keyword,
-                        const unordered_map<uint32, uint64> &label_decoder,
-                        VectorOfDoublesWriter *output ) {
-  std::vector<kaldi::ActivePath> paths;
-
-  if (keyword.Start() == fst::kNoStateId)
-    return;
-
-  kaldi::GenerateActivePaths(keyword, &paths, keyword.Start(),
-                  std::vector<kaldi::KwsLexicographicArc::Label>(),
-                  kaldi::KwsLexicographicArc::Weight::One());
-
-  for (int i = 0; i < paths.size(); ++i) {
-    std::vector<double> out;
-    double score;
-    int32 tbeg, tend, uid;
-
-    uint64 osymbol = label_decoder.find(paths[i].last)->second;
-    uid = kaldi::DecodeLabelUid(osymbol);
-    tbeg = paths[i].weight.Value2().Value1().Value();
-    tend = paths[i].weight.Value2().Value2().Value();
-    score = paths[i].weight.Value1().Value();
-
-    out.push_back(uid);
-    out.push_back(tbeg);
-    out.push_back(tend);
-    out.push_back(score);
-
-    for (int j = 0; j < paths[i].path.size(); ++j) {
-      out.push_back(paths[i].path[j]);
+    output.push_back(score);
+    if (paths != nullptr) {
+      for (int j = 0; j < (*paths)[i].size(); ++j)
+        output.push_back((*paths)[i][j]);
     }
-    output->Write(kwid, out);
+    writer->Write(kwid, output);
   }
 }
 
@@ -236,14 +143,14 @@ int main(int argc, char *argv[]) {
 
     std::string index_rspecifier = po.GetArg(1),
         keyword_rspecifier = po.GetArg(2),
-        result_wspecifier = po.GetArg(3),
+        results_wspecifier = po.GetArg(3),
         stats_wspecifier = po.GetOptArg(4);
 
     RandomAccessTableReader< VectorFstTplHolder<KwsLexicographicArc> >
                                                 index_reader(index_rspecifier);
     SequentialTableReader<VectorFstHolder> keyword_reader(keyword_rspecifier);
-    VectorOfDoublesWriter result_writer(result_wspecifier);
-    VectorOfDoublesWriter stats_writer(stats_wspecifier);
+    TableWriter<BasicVectorHolder<double> > results_writer(results_wspecifier),
+                                            stats_writer(stats_wspecifier);
 
 
     // Index has key "global"
@@ -257,34 +164,8 @@ int main(int argc, char *argv[]) {
     // disambiguation symbol on the input symbol side, which will not allow us
     // to do epsilon removal after composition with the keyword FST. They have
     // to traverse the resulting FST.
-    int32 label_count = 1;
-    unordered_map<uint64, uint32> label_encoder;
-    unordered_map<uint32, uint64> label_decoder;
-    for (StateIterator<KwsLexicographicFst> siter(index);
-                                           !siter.Done(); siter.Next()) {
-      StateId state_id = siter.Value();
-      for (MutableArcIterator<KwsLexicographicFst>
-           aiter(&index, state_id); !aiter.Done(); aiter.Next()) {
-        KwsLexicographicArc arc = aiter.Value();
-        // Skip the non-final arcs
-        if (index.Final(arc.nextstate) == Weight::Zero())
-          continue;
-        // Encode the input and output label of the final arc, and this is the
-        // new output label for this arc; set the input label to <epsilon>
-        uint64 osymbol = EncodeLabel(arc.ilabel, arc.olabel);
-        arc.ilabel = 0;
-        if (label_encoder.find(osymbol) == label_encoder.end()) {
-          arc.olabel = label_count;
-          label_encoder[osymbol] = label_count;
-          label_decoder[label_count] = osymbol;
-          label_count++;
-        } else {
-          arc.olabel = label_encoder[osymbol];
-        }
-        aiter.SetValue(arc);
-      }
-    }
-    ArcSort(&index, fst::ILabelCompare<KwsLexicographicArc>());
+    fst::internal::EncodeTable<KwsLexicographicArc> encode_table(kEncodeLabels);
+    EncodeKwsDisambiguationSymbols(&index, &encode_table);
 
     int32 n_done = 0;
     int32 n_fail = 0;
@@ -303,63 +184,30 @@ int main(int argc, char *argv[]) {
         keyword = tmp;
       }
 
-      KwsLexicographicFst keyword_fst;
-      KwsLexicographicFst result_fst;
-      Map(keyword, &keyword_fst, VectorFstToKwsLexicographicFstMapper());
-      Compose(keyword_fst, index, &result_fst);
+      bool success = true;
+      std::vector<std::tuple<int32, int32, int32, double> > results;
 
       if (stats_wspecifier != "") {
-        KwsLexicographicFst matched_seq(result_fst);
-        OutputDetailedStatistics(key,
-                                 matched_seq,
-                                 label_decoder,
-                                 &stats_writer);
+        KwsLexicographicFst matched_seq;
+        success = SearchKwsIndex(index, keyword, encode_table, n_best,
+                                 &results, &matched_seq);
+        std::vector<std::tuple<int32, int32, int32, double> > stats;
+        std::vector<std::vector<int32> > paths;
+        ComputeDetailedStatistics(matched_seq, encode_table, &stats, &paths);
+        WriteKWSResults(key, stats, &paths, frame_subsampling_factor,
+                        negative_tolerance, &stats_writer);
+      } else {
+        success = SearchKwsIndex(index, keyword, encode_table, n_best,
+                                 &results);
       }
 
-      Project(&result_fst, PROJECT_OUTPUT);
-      Minimize(&result_fst, (KwsLexicographicFst *) nullptr, kDelta, true);
-      ShortestPath(result_fst, &result_fst, n_best);
-      RmEpsilon(&result_fst);
-
-      // No result found
-      if (result_fst.Start() == kNoStateId)
-        continue;
-
-      // Got something here
-      double score;
-      int32 tbeg, tend, uid;
-      for (ArcIterator<KwsLexicographicFst>
-           aiter(result_fst, result_fst.Start()); !aiter.Done(); aiter.Next()) {
-        const KwsLexicographicArc &arc = aiter.Value();
-
-        // We're expecting a two-state FST
-        if (result_fst.Final(arc.nextstate) != Weight::One()) {
-          KALDI_WARN << "The resulting FST does not have "
-                     << "the expected structure for key " << key;
-          n_fail++;
-          continue;
-        }
-
-        uint64 osymbol = label_decoder[arc.olabel];
-        uid = static_cast<int32>(DecodeLabelUid(osymbol));
-        tbeg = arc.weight.Value2().Value1().Value();
-        tend = arc.weight.Value2().Value2().Value();
-        score = arc.weight.Value1().Value();
-
-        if (score < 0) {
-          if (score < negative_tolerance) {
-            KALDI_WARN << "Score out of expected range: " << score;
-          }
-          score = 0.0;
-        }
-        vector<double> result;
-        result.push_back(uid);
-        result.push_back(tbeg * frame_subsampling_factor);
-        result.push_back(tend * frame_subsampling_factor);
-        result.push_back(score);
-        result_writer.Write(key, result);
+      if (!success) {
+        KALDI_WARN << "Search failed for key " << key;
+        n_fail++;
       }
-
+      
+      WriteKWSResults(key, results, nullptr, frame_subsampling_factor,
+                      negative_tolerance, &results_writer);
       n_done++;
     }
 
diff --git a/src/kwsbin/lattice-to-kws-index.cc b/src/kwsbin/lattice-to-kws-index.cc
index fcd6b82..58d6b0f 100644
--- a/src/kwsbin/lattice-to-kws-index.cc
+++ b/src/kwsbin/lattice-to-kws-index.cc
@@ -115,6 +115,7 @@ int main(int argc, char *argv[]) {
         n_fail++;
         continue;
       }
+      int32 utterance_id = usymtab_reader.Value(key);
 
       // Topologically sort the lattice, if not already sorted.
       uint64 props = clat.Properties(fst::kFstProperties, false);
@@ -126,91 +127,16 @@ int main(int argc, char *argv[]) {
         }
       }
 
-      // Get the alignments
-      std::vector<int32> state_times;
-      CompactLatticeStateTimes(clat, &state_times);
-
-      // Cluster the arcs in the CompactLattice, write the cluster_id on the
-      // output label side.
-      // ClusterLattice() corresponds to the second part of the preprocessing in
-      // Dogan and Murat's paper -- clustering. Note that we do the first part
-      // of preprocessing (the weight pushing step) later when generating the
-      // factor transducer.
-      KALDI_VLOG(1) << "Arc clustering...";
-      bool success = false;
-      success = kaldi::ClusterLattice(&clat, state_times);
-      if (!success) {
-        KALDI_WARN << "State id's and alignments do not match for lattice "
-                   << key;
+      // Construct KWS index.
+      KwsLexicographicFst index_transducer;
+      if (!LatticeToKwsIndexDestructive(&clat, utterance_id, max_silence_frames,
+                                        max_states, allow_partial,
+                                        &index_transducer)) {
+        KALDI_WARN << "KWS index construction failed for lattice " << key;
         n_fail++;
         continue;
       }
 
-      // The next part is something new, not in the Dogan and Can paper.  It is
-      // necessary because we have epsilon arcs, due to silences, in our
-      // lattices.  We modify the factor transducer, while maintaining
-      // equivalence, to ensure that states don't have both epsilon *and*
-      // non-epsilon arcs entering them.  (and the same, with "entering"
-      // replaced with "leaving").  Later we will find out which states have
-      // non-epsilon arcs leaving/entering them and use it to be more selective
-      // in adding arcs to connect them with the initial/final states.  The goal
-      // here is to disallow silences at the beginning or ending of a keyword
-      // occurrence.
-      if (true) {
-        EnsureEpsilonProperty(&clat);
-        fst::TopSort(&clat);
-        // We have to recompute the state times because they will have changed.
-        CompactLatticeStateTimes(clat, &state_times);
-      }
-
-      // Generate factor transducer
-      // CreateFactorTransducer() corresponds to the "Factor Generation" part of
-      // Dogan and Murat's paper. But we also move the weight pushing step to
-      // this function as we have to compute the alphas and betas anyway.
-      KALDI_VLOG(1) << "Generating factor transducer...";
-      KwsProductFst factor_transducer;
-      int32 utterance_id = usymtab_reader.Value(key);
-      success = kaldi::CreateFactorTransducer(clat,
-                                              state_times,
-                                              utterance_id,
-                                              &factor_transducer);
-      if (!success) {
-        KALDI_WARN << "Cannot generate factor transducer for lattice " << key;
-        n_fail++;
-      }
-
-      MaybeDoSanityCheck(factor_transducer);
-
-      // Remove long silence arc
-      // We add the filtering step in our implementation. This is because gap
-      // between two successive words in a query term should be less than 0.5s
-      KALDI_VLOG(1) << "Removing long silence...";
-      RemoveLongSilences(max_silence_frames, state_times, &factor_transducer);
-
-      MaybeDoSanityCheck(factor_transducer);
-
-      // Do factor merging, and return a transducer in T*T*T semiring. This step
-      // corresponds to the "Factor Merging" part in Dogan and Murat's paper.
-      KALDI_VLOG(1) << "Merging factors...";
-      KwsLexicographicFst index_transducer;
-      DoFactorMerging(&factor_transducer, &index_transducer);
-
-      MaybeDoSanityCheck(index_transducer);
-
-      // Do factor disambiguation. It corresponds to the "Factor Disambiguation"
-      // step in Dogan and Murat's paper.
-      KALDI_VLOG(1) << "Doing factor disambiguation...";
-      DoFactorDisambiguation(&index_transducer);
-
-      MaybeDoSanityCheck(index_transducer);
-
-      // Optimize the above factor transducer. It corresponds to the
-      // "Optimization" step in the paper.
-      KALDI_VLOG(1) << "Optimizing factor transducer...";
-      OptimizeFactorTransducer(&index_transducer, max_states, allow_partial);
-
-      MaybeDoSanityCheck(index_transducer);
-
       // Write result
       index_writer.Write(key, index_transducer);
 
diff --git a/src/lat/determinize-lattice-pruned.cc b/src/lat/determinize-lattice-pruned.cc
index dbdd9af..9fa9eaf 100644
--- a/src/lat/determinize-lattice-pruned.cc
+++ b/src/lat/determinize-lattice-pruned.cc
@@ -1344,6 +1344,12 @@ typename ArcTpl<Weight>::Label DeterminizeLatticeInsertPhones(
   return first_phone_label;
 }
 
+// instantiate for type LatticeWeight
+template
+ArcTpl<kaldi::LatticeWeight>::Label DeterminizeLatticeInsertPhones(
+    const kaldi::TransitionModel &trans_model,
+    MutableFst<ArcTpl<kaldi::LatticeWeight> > *fst);
+
 template<class Weight>
 void DeterminizeLatticeDeletePhones(
     typename ArcTpl<Weight>::Label first_phone_label,
diff --git a/src/lat/word-align-lattice.h b/src/lat/word-align-lattice.h
index e688e3e..6345ce1 100644
--- a/src/lat/word-align-lattice.h
+++ b/src/lat/word-align-lattice.h
@@ -118,7 +118,7 @@ struct WordBoundaryInfoNewOpts {
 
 struct WordBoundaryInfo {
   // This initializer will be deleted eventually.
-  WordBoundaryInfo(const WordBoundaryInfoOpts &opts); // Initialize from
+  explicit WordBoundaryInfo(const WordBoundaryInfoOpts &opts); // Initialize from
   // options class.  Note: this throws.  Don't try to catch this error
   // and continue; catching errors thrown from initializers is dangerous.
   // Note: the following vectors are initialized from the corresponding
@@ -127,7 +127,7 @@ struct WordBoundaryInfo {
   // silence phones behave in this way.
 
   // This initializer is to be used in future.
-  WordBoundaryInfo(const WordBoundaryInfoNewOpts &opts);
+  explicit WordBoundaryInfo(const WordBoundaryInfoNewOpts &opts);
   WordBoundaryInfo(const WordBoundaryInfoNewOpts &opts,
                    std::string word_boundary_file);
 
diff --git a/src/matrix/kaldi-matrix.cc b/src/matrix/kaldi-matrix.cc
index 63b5ba9..62a377d 100644
--- a/src/matrix/kaldi-matrix.cc
+++ b/src/matrix/kaldi-matrix.cc
@@ -759,7 +759,7 @@ Matrix<Real>::Matrix (const Matrix<Real> & M):
 
 /// Copy constructor from another type.
 template<typename Real>
-template<typename OtherReal>
+template<typename OtherReal, typename std::enable_if<!std::is_same<OtherReal,Real>::value>::type*>
 Matrix<Real>::Matrix(const MatrixBase<OtherReal> & M,
                      MatrixTransposeType trans) : MatrixBase<Real>() {
   if (trans == kNoTrans) {
@@ -1021,7 +1021,8 @@ void MatrixBase<Real>::CopyRowsFromVec(const VectorBase<Real> &rv) {
 
 template<typename Real>
 template<typename OtherReal>
-void MatrixBase<Real>::CopyRowsFromVec(const VectorBase<OtherReal> &rv) {
+typename std::enable_if<!std::is_same<OtherReal,Real>::value>::type
+MatrixBase<Real>::CopyRowsFromVec(const VectorBase<OtherReal> &rv) {
   if (rv.Dim() == num_rows_*num_cols_) {
     const OtherReal *rv_data = rv.Data();
     for (MatrixIndexT r = 0; r < num_rows_; r++) {
@@ -1347,6 +1348,11 @@ void MatrixBase<Real>::Set(Real value) {
   }
 }
 
+template<typename Real>
+void MatrixBase<Real>::Set(MatrixIndexT r, MatrixIndexT c, Real value) {
+      (*this)(r, c) = value;
+}
+
 template<typename Real>
 void MatrixBase<Real>::SetUnit() {
   SetZero();
diff --git a/src/matrix/kaldi-matrix.h b/src/matrix/kaldi-matrix.h
index bc95c91..88debbc 100644
--- a/src/matrix/kaldi-matrix.h
+++ b/src/matrix/kaldi-matrix.h
@@ -126,6 +126,8 @@ class MatrixBase {
   void SetZero();
   /// Sets all elements to a specific value.
   void Set(Real);
+  /// Set the matrix item at the given index to the specified value.
+  void Set(MatrixIndexT r, MatrixIndexT c, Real f);
   /// Sets to zero, except ones along diagonal [for non-square matrices too]
   void SetUnit();
   /// Sets to random values of a normal distribution
@@ -168,7 +170,8 @@ class MatrixBase {
   void CopyRowsFromVec(const CuVectorBase<Real> &v);
 
   template<typename OtherReal>
-  void CopyRowsFromVec(const VectorBase<OtherReal> &v);
+  typename std::enable_if<!std::is_same<OtherReal,Real>::value>::type
+  CopyRowsFromVec(const VectorBase<OtherReal> &v);
 
   /// Copies vector into matrix, column-by-column.
   /// Note that rv.Dim() must either equal NumRows()*NumCols() or NumRows();
@@ -855,7 +858,8 @@ class Matrix : public MatrixBase<Real> {
   Matrix(const Matrix<Real> & M);  //  (cannot make explicit)
 
   /// Copy constructor: as above, but from another type.
-  template<typename OtherReal>
+  template<typename OtherReal,
+           typename std::enable_if<!std::is_same<OtherReal,Real>::value>::type* = nullptr >
   explicit Matrix(const MatrixBase<OtherReal> & M,
                     MatrixTransposeType trans = kNoTrans);
 
@@ -1014,9 +1018,14 @@ class SubMatrix : public MatrixBase<Real> {
   MatrixBase<Real> (other.data_, other.num_cols_, other.num_rows_,
                     other.stride_) {}
 
- private:
-  /// Disallow assignment.
-  SubMatrix<Real> &operator = (const SubMatrix<Real> &other);
+   /// Assignment operator
+  SubMatrix<Real> &operator = (const SubMatrix<Real> &other) {
+    this->data_ = other.data_;
+    this->num_cols_ = other.num_cols_;
+    this->num_rows_ = other.num_rows_;
+    this->stride_ = other.stride_;
+    return *this;
+  }
 };
 /// @} End of "addtogroup matrix_funcs_io".
 
diff --git a/src/matrix/kaldi-vector.cc b/src/matrix/kaldi-vector.cc
index ccc7e89..9f04b0e 100644
--- a/src/matrix/kaldi-vector.cc
+++ b/src/matrix/kaldi-vector.cc
@@ -48,7 +48,8 @@ template
 double VecVec<>(const VectorBase<double> &a,
                 const VectorBase<double> &b);
 
-template<typename Real, typename OtherReal>
+template<typename Real, typename OtherReal,
+         typename std::enable_if<!std::is_same<OtherReal,Real>::value>::type*>
 Real VecVec(const VectorBase<Real> &ra,
             const VectorBase<OtherReal> &rb) {
   MatrixIndexT adim = ra.Dim();
@@ -253,7 +254,8 @@ void VectorBase<Real>::CopyFromPtr(const Real *data, MatrixIndexT sz) {
 
 template<typename Real>
 template<typename OtherReal>
-void VectorBase<Real>::CopyFromVec(const VectorBase<OtherReal> &other) {
+typename std::enable_if<!std::is_same<OtherReal,Real>::value>::type
+VectorBase<Real>::CopyFromVec(const VectorBase<OtherReal> &other) {
   KALDI_ASSERT(dim_ == other.Dim());
   Real * __restrict__  ptr = data_;
   const OtherReal * __restrict__ other_ptr = other.Data();
@@ -344,6 +346,13 @@ void VectorBase<Real>::Set(Real f) {
   }
 }
 
+template<typename Real>
+void VectorBase<Real>::Set(MatrixIndexT i, Real f) {
+  KALDI_PARANOID_ASSERT(static_cast<UnsignedMatrixIndexT>(i) <
+               static_cast<UnsignedMatrixIndexT>(dim_));
+  data_[i] = f;
+}
+
 template<typename Real>
 void VectorBase<Real>::CopyRowsFromMat(const MatrixBase<Real> &mat) {
   KALDI_ASSERT(dim_ == mat.NumCols() * mat.NumRows());
@@ -982,7 +991,8 @@ void VectorBase<Real>::ReplaceValue(Real orig, Real changed) {
 
 template<typename Real>
 template<typename OtherReal>
-void VectorBase<Real>::MulElements(const VectorBase<OtherReal> &v) {
+typename std::enable_if<!std::is_same<OtherReal,Real>::value>::type
+VectorBase<Real>::MulElements(const VectorBase<OtherReal> &v) {
   KALDI_ASSERT(dim_ == v.Dim());
   const OtherReal *other_ptr = v.Data();
   for (MatrixIndexT i = 0; i < dim_; i++) {
@@ -1017,7 +1027,8 @@ void VectorBase<Real>::DivElements(const VectorBase<Real> &v) {
 
 template<typename Real>
 template<typename OtherReal>
-void VectorBase<Real>::DivElements(const VectorBase<OtherReal> &v) {
+typename std::enable_if<!std::is_same<OtherReal,Real>::value>::type
+VectorBase<Real>::DivElements(const VectorBase<OtherReal> &v) {
   KALDI_ASSERT(dim_ == v.Dim());
   const OtherReal *other_ptr = v.Data();
   for (MatrixIndexT i = 0; i < dim_; i++) {
@@ -1062,7 +1073,8 @@ void VectorBase<double>::AddVec(const double alpha, const VectorBase<float> &v);
 
 template<typename Real>
 template<typename OtherReal>
-void VectorBase<Real>::AddVec2(const Real alpha, const VectorBase<OtherReal> &v) {
+typename std::enable_if<!std::is_same<OtherReal,Real>::value>::type
+VectorBase<Real>::AddVec2(const Real alpha, const VectorBase<OtherReal> &v) {
   KALDI_ASSERT(dim_ == v.dim_);
   // remove __restrict__ if it causes compilation problems.
   Real *__restrict__ data = data_;
diff --git a/src/matrix/kaldi-vector.h b/src/matrix/kaldi-vector.h
index a5baa3c..0791d40 100644
--- a/src/matrix/kaldi-vector.h
+++ b/src/matrix/kaldi-vector.h
@@ -43,12 +43,15 @@ class VectorBase {
   /// Set vector to all zeros.
   void SetZero();
 
-  /// Returns true if matrix is all zeros.
+  /// Returns true if vector is all zeros.
   bool IsZero(Real cutoff = 1.0e-06) const;     // replace magic number
 
-  /// Set all members of a vector to a specified value.
+  /// Set all vector items to the specified value.
   void Set(Real f);
 
+ /// Set the vector item at the given index to the specified value.
+  void Set(MatrixIndexT i, Real f);
+
   /// Set vector to random normally-distributed noise.
   void SetRandn();
 
@@ -114,7 +117,8 @@ class VectorBase {
 
   /// Copy data from another vector of different type (double vs. float)
   template<typename OtherReal>
-  void CopyFromVec(const VectorBase<OtherReal> &v);
+  typename std::enable_if<!std::is_same<OtherReal,Real>::value>::type
+  CopyFromVec(const VectorBase<OtherReal> &v);
 
   /// Copy from CuVector.  This is defined in ../cudamatrix/cu-vector.h
   template<typename OtherReal>
@@ -205,7 +209,8 @@ class VectorBase {
   /// Add vector : *this = *this + alpha * rv^2  [element-wise squaring],
   /// with casting between floats and doubles.
   template<typename OtherReal>
-  void AddVec2(const Real alpha, const VectorBase<OtherReal> &v);
+  typename std::enable_if<!std::is_same<OtherReal,Real>::value>::type
+  AddVec2(const Real alpha, const VectorBase<OtherReal> &v);
 
   /// Add matrix times vector : this <-- beta*this + alpha*M*v.
   /// Calls BLAS GEMV.
@@ -238,13 +243,15 @@ class VectorBase {
   void MulElements(const VectorBase<Real> &v);
   /// Multiply element-by-element by another vector of different type.
   template<typename OtherReal>
-  void MulElements(const VectorBase<OtherReal> &v);
+  typename std::enable_if<!std::is_same<OtherReal,Real>::value>::type
+  MulElements(const VectorBase<OtherReal> &v);
 
   /// Divide element-by-element by a vector.
   void DivElements(const VectorBase<Real> &v);
   /// Divide element-by-element by a vector of different type.
   template<typename OtherReal>
-  void DivElements(const VectorBase<OtherReal> &v);
+  typename std::enable_if<!std::is_same<OtherReal,Real>::value>::type
+  DivElements(const VectorBase<OtherReal> &v);
 
   /// Add a constant to each element of a vector.
   void Add(Real c);
@@ -432,7 +439,8 @@ class Vector: public VectorBase<Real> {
   }
 
   /// Type conversion constructor.
-  template<typename OtherReal>
+  template<typename OtherReal,
+           typename std::enable_if<!std::is_same<OtherReal,Real>::value>::type* = nullptr >
   explicit Vector(const VectorBase<OtherReal> &v): VectorBase<Real>() {
     Resize(v.Dim(), kUndefined);
     this->CopyFromVec(v);
@@ -542,11 +550,15 @@ class SubVector : public VectorBase<Real> {
     this->dim_   = matrix.NumCols();
   }
 
+  /// Assignment operator
+  SubVector<Real> &operator = (const SubVector<Real> &other) {
+    this->data_ = other.data_;
+    this->dim_ = other.dim_;
+    return *this;
+  }
+
   ~SubVector() {}  ///< Destructor (does nothing; no pointers are owned here).
 
- private:
-  /// Disallow assignment operator.
-  SubVector & operator = (const SubVector &other) {}
 };
 
 /// @} end of "addtogroup matrix_group"
@@ -589,7 +601,8 @@ inline void AssertEqual(VectorBase<Real> &a, VectorBase<Real> &b,
 template<typename Real>
 Real VecVec(const VectorBase<Real> &v1, const VectorBase<Real> &v2);
 
-template<typename Real, typename OtherReal>
+template<typename Real, typename OtherReal,
+         typename std::enable_if<!std::is_same<OtherReal,Real>::value>::type* = nullptr >
 Real VecVec(const VectorBase<Real> &v1, const VectorBase<OtherReal> &v2);
 
 
diff --git a/src/matrix/matrix-common.h b/src/matrix/matrix-common.h
index f7047d7..b10021c 100644
--- a/src/matrix/matrix-common.h
+++ b/src/matrix/matrix-common.h
@@ -29,24 +29,24 @@ namespace kaldi {
 // this enums equal to CblasTrans and CblasNoTrans constants from CBLAS library
 // we are writing them as literals because we don't want to include here matrix/kaldi-blas.h,
 // which puts many symbols into global scope (like "real") via the header f2c.h 
-typedef enum {
+typedef enum MatrixTransposeType {
   kTrans    = 112, // = CblasTrans
   kNoTrans  = 111  // = CblasNoTrans
 } MatrixTransposeType;
 
-typedef enum {
+typedef enum MatrixResizeType {
   kSetZero,
   kUndefined,
   kCopyData
 } MatrixResizeType;
 
 
-typedef enum {
+typedef enum MatrixStrideType {
   kDefaultStride,
   kStrideEqualNumCols,
 } MatrixStrideType;
 
-typedef enum {
+typedef enum SpCopyType {
   kTakeLower,
   kTakeUpper,
   kTakeMean,
diff --git a/src/matrix/packed-matrix.h b/src/matrix/packed-matrix.h
index 722d932..bd96af1 100644
--- a/src/matrix/packed-matrix.h
+++ b/src/matrix/packed-matrix.h
@@ -52,7 +52,8 @@ template<typename Real> class PackedMatrix {
     CopyFromPacked(orig);
   }
 
-  template<typename OtherReal>
+  template<typename OtherReal,
+  typename std::enable_if<!std::is_same<OtherReal,Real>::value>::type* = nullptr >
   explicit PackedMatrix(const PackedMatrix<OtherReal> &orig) : data_(NULL) {
     Resize(orig.NumRows(), kUndefined);
     CopyFromPacked(orig);
diff --git a/src/matrix/sp-matrix.cc b/src/matrix/sp-matrix.cc
index 224ef39..6bf45f3 100644
--- a/src/matrix/sp-matrix.cc
+++ b/src/matrix/sp-matrix.cc
@@ -363,7 +363,8 @@ float TraceSpSp(const SpMatrix<float> &A, const SpMatrix<float> &B) {
 }
 
 
-template<typename Real, typename OtherReal>
+template<typename Real, typename OtherReal,
+         typename std::enable_if<!std::is_same<OtherReal,Real>::value>::type*>
 Real TraceSpSp(const SpMatrix<Real> &A, const SpMatrix<OtherReal> &B) {
   KALDI_ASSERT(A.NumRows() == B.NumRows());
   Real ans = 0.0;
diff --git a/src/matrix/sp-matrix.h b/src/matrix/sp-matrix.h
index 26d9ad6..841bd89 100644
--- a/src/matrix/sp-matrix.h
+++ b/src/matrix/sp-matrix.h
@@ -57,7 +57,8 @@ class SpMatrix : public PackedMatrix<Real> {
   SpMatrix(const SpMatrix<Real> &orig)
       : PackedMatrix<Real>(orig) {}
 
-  template<typename OtherReal>
+  template<typename OtherReal,
+  typename std::enable_if<!std::is_same<OtherReal,Real>::value>::type* = nullptr >
   explicit SpMatrix(const SpMatrix<OtherReal> &orig)
       : PackedMatrix<Real>(orig) {}
 
@@ -87,7 +88,7 @@ class SpMatrix : public PackedMatrix<Real> {
   }
 
   template<typename OtherReal>
-  void CopyFromSp(const SpMatrix<OtherReal> &other) {
+  typename std::enable_if<!std::is_same<OtherReal, Real>::value>::type CopyFromSp(const SpMatrix<OtherReal> &other) {
     PackedMatrix<Real>::CopyFromPacked(other);
   }
 
@@ -386,7 +387,8 @@ inline void AssertEqual(const SpMatrix<Real> &A,
 
 
 /// Returns tr(A B).
-template<typename Real, typename OtherReal>
+template<typename Real, typename OtherReal,
+         typename std::enable_if<!std::is_same<OtherReal,Real>::value>::type* = nullptr >
 Real TraceSpSp(const SpMatrix<Real> &A, const SpMatrix<OtherReal> &B);
 
 
diff --git a/src/matrix/tp-matrix.h b/src/matrix/tp-matrix.h
index e3b0870..0698169 100644
--- a/src/matrix/tp-matrix.h
+++ b/src/matrix/tp-matrix.h
@@ -47,7 +47,7 @@ class TpMatrix : public PackedMatrix<Real> {
   explicit TpMatrix(const CuTpMatrix<Real> &cu);
 
 
-  template<typename OtherReal> explicit TpMatrix(const TpMatrix<OtherReal>& orig)
+  template<typename OtherReal, typename std::enable_if<!std::is_same<OtherReal, Real>::value>::type* = nullptr> explicit TpMatrix(const TpMatrix<OtherReal>& orig)
       : PackedMatrix<Real>(orig) {}
 
   Real operator() (MatrixIndexT r, MatrixIndexT c) const {
@@ -105,7 +105,7 @@ class TpMatrix : public PackedMatrix<Real> {
     PackedMatrix<Real>::CopyFromPacked(other);
   }
 
-  template<typename OtherReal> void CopyFromTp(const TpMatrix<OtherReal> &other) {
+  template<typename OtherReal> typename std::enable_if<!std::is_same<OtherReal, Real>::value>::type CopyFromTp(const TpMatrix<OtherReal> &other) {
     PackedMatrix<Real>::CopyFromPacked(other);
   }
 
diff --git a/src/nnet3/am-nnet-simple.h b/src/nnet3/am-nnet-simple.h
index c3d8301..831df09 100644
--- a/src/nnet3/am-nnet-simple.h
+++ b/src/nnet3/am-nnet-simple.h
@@ -71,12 +71,16 @@ class AmNnetSimple {
   /// call SetContext() afterward.
   Nnet &GetNnet() { return nnet_; }
 
+  Nnet *GetNnetPtr() { return &nnet_; }
+
   void SetNnet(const Nnet &nnet);
 
   void SetPriors(const VectorBase<BaseFloat> &priors);
 
   const VectorBase<BaseFloat> &Priors() const { return priors_; }
 
+  VectorBase<BaseFloat> *PriorsPtr() { return &priors_; }
+
   std::string Info() const;
 
   /// Minimum left context required to compute an output.
diff --git a/src/nnet3/decodable-online-looped.cc b/src/nnet3/decodable-online-looped.cc
index 7514386..4d2b0b8 100644
--- a/src/nnet3/decodable-online-looped.cc
+++ b/src/nnet3/decodable-online-looped.cc
@@ -239,12 +239,28 @@ BaseFloat DecodableNnetLoopedOnline::LogLikelihood(int32 subsampled_frame,
                                                     int32 index) {
   subsampled_frame += frame_offset_;
   EnsureFrameIsComputed(subsampled_frame);
-  // note: we index by 'inde
+  // note: we index by 'index - 1'
   return current_log_post_(
       subsampled_frame - current_log_post_subsampled_offset_,
       index - 1);
 }
 
+// faster direct access to the loglikelihoods by row
+void DecodableNnetLoopedOnlineBase::LogLikelihoods(int32 subsampled_frame,
+						     Vector<BaseFloat> *loglikes) {
+  EnsureFrameIsComputed(subsampled_frame);
+  loglikes->Resize(current_log_post_.NumCols());
+  loglikes->CopyFromVec(current_log_post_.Row(subsampled_frame - current_log_post_subsampled_offset_));
+}
+
+void DecodableNnetLoopedOnlineBase::LogLikelihoods(int32 subsampled_frame,
+						   int32 num_frames,
+						   Matrix<BaseFloat> *loglikes) {
+  KALDI_ASSERT(num_frames > 0);
+  EnsureFrameIsComputed(subsampled_frame + num_frames - 1);
+  loglikes->Resize(num_frames, current_log_post_.NumCols());
+  loglikes->CopyFromMat(current_log_post_.RowRange(subsampled_frame - current_log_post_subsampled_offset_, num_frames));
+}
 
 BaseFloat DecodableAmNnetLoopedOnline::LogLikelihood(int32 subsampled_frame,
                                                     int32 index) {
diff --git a/src/nnet3/decodable-online-looped.h b/src/nnet3/decodable-online-looped.h
index cc79e58..e002066 100644
--- a/src/nnet3/decodable-online-looped.h
+++ b/src/nnet3/decodable-online-looped.h
@@ -81,6 +81,10 @@ class DecodableNnetLoopedOnlineBase: public DecodableInterface {
     return info_.opts.frame_subsampling_factor;
   }
 
+  // Supply access to the loglikelihoods by row, for efficiency with pykaldi
+  void LogLikelihoods(int32 subsampled_frame, Vector<BaseFloat> *loglikes);
+  void LogLikelihoods(int32 subsampled_frame, int32 num_frames, Matrix<BaseFloat> *loglikes);
+
   /// Sets the frame offset value. Frame offset is initialized to 0 when the
   /// decodable object is constructed and stays as 0 unless this method is
   /// called. This method is useful when we want to reset the decoder state,
diff --git a/src/nnet3/nnet-analyze.h b/src/nnet3/nnet-analyze.h
index 7746603..cb6836f 100644
--- a/src/nnet3/nnet-analyze.h
+++ b/src/nnet3/nnet-analyze.h
@@ -221,6 +221,7 @@ class ComputationVariables {
 struct Access {
   int32 command_index;
   AccessType access_type;
+  Access() {}
   Access(int32 command_index, AccessType access_type):
       command_index(command_index), access_type(access_type) { }
   bool operator < (const Access &other) const {
diff --git a/src/nnet3/nnet-computation-graph.h b/src/nnet3/nnet-computation-graph.h
index c310444..b7d2c0a 100644
--- a/src/nnet3/nnet-computation-graph.h
+++ b/src/nnet3/nnet-computation-graph.h
@@ -301,7 +301,7 @@ class CindexSet {
 
   /// with this constructor, represents the set of all Cindexes that exist
   /// in the graph.
-  CindexSet(const ComputationGraph &graph);
+  explicit CindexSet(const ComputationGraph &graph);
 
   /// with this constructor, represents the set of all Cindexes that exist in
   /// the graph and which are computable.  If treat_unknown_as_computable is
diff --git a/src/nnet3/nnet-descriptor.h b/src/nnet3/nnet-descriptor.h
index 8e2373f..da248ad 100644
--- a/src/nnet3/nnet-descriptor.h
+++ b/src/nnet3/nnet-descriptor.h
@@ -224,7 +224,7 @@ class SwitchingForwardingDescriptor: public ForwardingDescriptor {
   virtual BaseFloat GetScaleForNode(int32 node_index) const;
 
   // takes ownership of items in src.
-  SwitchingForwardingDescriptor(std::vector<ForwardingDescriptor*> &src):
+  SwitchingForwardingDescriptor(const std::vector<ForwardingDescriptor*> &src):
       src_(src) { }
   virtual ~SwitchingForwardingDescriptor() { DeletePointers(&src_); }
  private:
diff --git a/src/nnet3/nnet-example-utils.h b/src/nnet3/nnet-example-utils.h
index 02fb31d..47f1520 100644
--- a/src/nnet3/nnet-example-utils.h
+++ b/src/nnet3/nnet-example-utils.h
@@ -170,7 +170,7 @@ struct ChunkTimeInfo {
 class UtteranceSplitter {
  public:
 
-  UtteranceSplitter(const ExampleGenerationConfig &config);
+  explicit UtteranceSplitter(const ExampleGenerationConfig &config);
 
 
   const ExampleGenerationConfig& Config() const { return config_; }
diff --git a/src/nnet3/nnet-optimize.h b/src/nnet3/nnet-optimize.h
index 0804729..6d628f7 100644
--- a/src/nnet3/nnet-optimize.h
+++ b/src/nnet3/nnet-optimize.h
@@ -230,6 +230,10 @@ class CachingOptimizingCompiler {
 
   ~CachingOptimizingCompiler();
 
+  const NnetComputation* CompilePtr(const ComputationRequest &request) {
+    return Compile(request).get();
+  }
+
   /// Does the compilation and returns a const pointer to the result, which is
   /// owned by this class, not the caller.  It calls ComputeCudaIndexes() for
   /// you, because you wouldn't be able to do this on a const object.
@@ -342,12 +346,6 @@ void LimitDerivativeTimes(const Nnet &nnet,
                           const NnetOptimizeOptions &opts,
                           NnetComputation *computation);
 
-/// This consolidates the model-update parts of the backprop into larger
-/// operations (applicable mostly to recurrent setups)-- internally it uses
-/// class ModelUpdateConsolidator.  Will fail if called a
-/// second time.
-void ConsolidateModelUpdate(const Nnet &nnet,
-                            NnetComputation *computation);
 
 /// This converts addition operations (things with Add in their names) to
 /// copy operations (things with Copy in their names).  This is slightly
diff --git a/src/nnet3/nnet-simple-component.cc b/src/nnet3/nnet-simple-component.cc
index 337e7ab..64c6502 100644
--- a/src/nnet3/nnet-simple-component.cc
+++ b/src/nnet3/nnet-simple-component.cc
@@ -4630,7 +4630,7 @@ void CompositeComponent::InitFromConfig(ConfigLine *cfl) {
   this->Init(components, max_rows_process);
 }
 
-const Component* CompositeComponent::GetComponent(int32 i) const {
+Component* CompositeComponent::GetComponent(int32 i) {
   KALDI_ASSERT(static_cast<size_t>(i) < components_.size());
   return components_[i];
 }
diff --git a/src/nnet3/nnet-simple-component.h b/src/nnet3/nnet-simple-component.h
index 546176f..f913467 100644
--- a/src/nnet3/nnet-simple-component.h
+++ b/src/nnet3/nnet-simple-component.h
@@ -998,7 +998,7 @@ class FixedAffineComponent: public Component {
   // Copy constructor from AffineComponent-- can be used when we're done
   // training a particular part of the model and want to efficiently disable
   // further training.
-  FixedAffineComponent(const AffineComponent &c);
+  explicit FixedAffineComponent(const AffineComponent &c);
 
   /// matrix should be of size input-dim+1 to output-dim, last col is offset
   void Init(const CuMatrixBase<BaseFloat> &matrix);
@@ -2041,7 +2041,7 @@ class CompositeComponent: public UpdatableComponent {
   /// Gets the ith component in this component.
   /// The ordering is the same as in the config line. The caller
   /// does not own the received component.
-  const Component* GetComponent(int32 i) const;
+  Component* GetComponent(int32 i);
   /// Sets the ith component. After this call, CompositeComponent owns
   /// the reference to the argument component. Frees the previous
   /// ith component.
diff --git a/src/online2/online-endpoint.cc b/src/online2/online-endpoint.cc
index 2a1c03e..55ac7c5 100644
--- a/src/online2/online-endpoint.cc
+++ b/src/online2/online-endpoint.cc
@@ -174,5 +174,22 @@ bool EndpointDetected<LatticeIncrementalOnlineDecoderTpl<fst::VectorGrammarFst >
     BaseFloat frame_shift_in_seconds,
     const LatticeIncrementalOnlineDecoderTpl<fst::VectorGrammarFst > &decoder);
 
+/*pykaldi*/
+
+template
+bool EndpointDetected<LatticeIncrementalOnlineDecoderTpl<fst::GrammarFst > >(
+    const OnlineEndpointConfig &config,
+    const TransitionModel &tmodel,
+    BaseFloat frame_shift_in_seconds,
+    const LatticeIncrementalOnlineDecoderTpl<fst::GrammarFst > &decoder);
+
+/*pykaldi*/
+
+template
+bool EndpointDetected<LatticeFasterOnlineDecoderTpl<fst::GrammarFst > >(
+    const OnlineEndpointConfig &config,
+    const TransitionModel &tmodel,
+    BaseFloat frame_shift_in_seconds,
+    const LatticeFasterOnlineDecoderTpl<fst::GrammarFst > &decoder);
 
 }  // namespace kaldi
diff --git a/src/online2/online-feature-pipeline.h b/src/online2/online-feature-pipeline.h
index 6196a3b..6834c6b 100644
--- a/src/online2/online-feature-pipeline.h
+++ b/src/online2/online-feature-pipeline.h
@@ -114,7 +114,7 @@ struct OnlineFeaturePipelineConfig {
       feature_type("mfcc"), add_pitch(false), add_deltas(true),
       splice_feats(false) { }
 
-  OnlineFeaturePipelineConfig(
+  explicit OnlineFeaturePipelineConfig(
       const OnlineFeaturePipelineCommandLineConfig &cmdline_config);
 
   BaseFloat FrameShiftInSeconds() const;
diff --git a/src/online2/online-gmm-decoding.h b/src/online2/online-gmm-decoding.h
index 1c6a478..d8e4cf0 100644
--- a/src/online2/online-gmm-decoding.h
+++ b/src/online2/online-gmm-decoding.h
@@ -165,7 +165,7 @@ struct OnlineGmmDecodingConfig {
    objects in this header. */
 class OnlineGmmDecodingModels {
  public:
-  OnlineGmmDecodingModels(const OnlineGmmDecodingConfig &config);
+  explicit OnlineGmmDecodingModels(const OnlineGmmDecodingConfig &config);
 
   const TransitionModel &GetTransitionModel() const;
 
diff --git a/src/online2/online-ivector-feature.cc b/src/online2/online-ivector-feature.cc
index 6c67793..6a96d28 100644
--- a/src/online2/online-ivector-feature.cc
+++ b/src/online2/online-ivector-feature.cc
@@ -593,6 +593,12 @@ void OnlineSilenceWeighting::ComputeCurrentTraceback<fst::VectorGrammarFst >(
     const LatticeFasterOnlineDecoderTpl<fst::VectorGrammarFst > &decoder,
     bool use_final_probs);
 
+/*pykaldi*/
+template
+void OnlineSilenceWeighting::ComputeCurrentTraceback<fst::GrammarFst >(
+    const LatticeFasterOnlineDecoderTpl<fst::GrammarFst > &decoder,
+    bool use_final_probs);
+
 template
 void OnlineSilenceWeighting::ComputeCurrentTraceback<fst::Fst<fst::StdArc> >(
     const LatticeIncrementalOnlineDecoderTpl<fst::Fst<fst::StdArc> > &decoder,
@@ -606,6 +612,11 @@ void OnlineSilenceWeighting::ComputeCurrentTraceback<fst::VectorGrammarFst >(
     const LatticeIncrementalOnlineDecoderTpl<fst::VectorGrammarFst > &decoder,
     bool use_final_probs);
 
+/*pykaldi*/
+template
+void OnlineSilenceWeighting::ComputeCurrentTraceback<fst::GrammarFst >(
+    const LatticeIncrementalOnlineDecoderTpl<fst::GrammarFst > &decoder,
+    bool use_final_probs);
 
 void OnlineSilenceWeighting::GetDeltaWeights(
     int32 num_frames_ready, int32 first_decoder_frame,
diff --git a/src/online2/online-ivector-feature.h b/src/online2/online-ivector-feature.h
index 3187071..4f8f68b 100644
--- a/src/online2/online-ivector-feature.h
+++ b/src/online2/online-ivector-feature.h
@@ -190,7 +190,7 @@ struct OnlineIvectorExtractionInfo {
   bool greedy_ivector_extractor;
   BaseFloat max_remembered_frames;
 
-  OnlineIvectorExtractionInfo(const OnlineIvectorExtractionConfig &config);
+  explicit OnlineIvectorExtractionInfo(const OnlineIvectorExtractionConfig &config);
 
   void Init(const OnlineIvectorExtractionConfig &config);
 
@@ -220,7 +220,7 @@ struct OnlineIvectorExtractorAdaptationState {
   OnlineIvectorEstimationStats ivector_stats;
 
   /// This constructor initializes adaptation-state with no prior speaker history.
-  OnlineIvectorExtractorAdaptationState(const OnlineIvectorExtractionInfo &info):
+  explicit OnlineIvectorExtractorAdaptationState(const OnlineIvectorExtractionInfo &info):
       cmvn_state(info.global_cmvn_stats),
       ivector_stats(info.extractor.IvectorDim(),
                     info.extractor.PriorOffset(),
diff --git a/src/online2/online-nnet2-feature-pipeline.h b/src/online2/online-nnet2-feature-pipeline.h
index ebc7045..030ea1b 100644
--- a/src/online2/online-nnet2-feature-pipeline.h
+++ b/src/online2/online-nnet2-feature-pipeline.h
@@ -139,7 +139,7 @@ struct OnlineNnet2FeaturePipelineInfo {
   OnlineNnet2FeaturePipelineInfo():
       feature_type("mfcc"), add_pitch(false), use_cmvn(false) { }
 
-  OnlineNnet2FeaturePipelineInfo(
+  explicit OnlineNnet2FeaturePipelineInfo(
       const OnlineNnet2FeaturePipelineConfig &config);
 
   BaseFloat FrameShiftInSeconds() const;
@@ -179,6 +179,11 @@ struct OnlineNnet2FeaturePipelineInfo {
   BaseFloat GetSamplingFrequency();
 
   int32 IvectorDim() { return ivector_extractor_info.extractor.IvectorDim(); }
+
+  OnlineIvectorExtractionInfo *IvectorExtractionInfoPtr() {
+    return &ivector_extractor_info;
+  }
+
  private:
   KALDI_DISALLOW_COPY_AND_ASSIGN(OnlineNnet2FeaturePipelineInfo);
 };
@@ -274,6 +279,13 @@ class OnlineNnet2FeaturePipeline: public OnlineFeatureInterface {
     return ivector_feature_;
   }
 
+  // Benjamin: pyclif was having issues with the overlaoded const below I assume,
+  // something about a deleted function, so I created this function just for pykaldi
+  // Its identical to OnlineIvectorFeature *IvectorFeature() and makes pyclif happy
+  OnlineIvectorFeature *IvectorFeaturePyKaldi() {
+    return ivector_feature_;
+  }
+
   /// A const accessor for the iVector extractor. Returns NULL if iVectors are
   /// not being used.
   const OnlineIvectorFeature *IvectorFeature() const {
diff --git a/src/online2/online-nnet3-decoding.cc b/src/online2/online-nnet3-decoding.cc
index 4af8bc5..049339a 100644
--- a/src/online2/online-nnet3-decoding.cc
+++ b/src/online2/online-nnet3-decoding.cc
@@ -99,5 +99,6 @@ bool SingleUtteranceNnet3DecoderTpl<FST>::EndpointDetected(
 template class SingleUtteranceNnet3DecoderTpl<fst::Fst<fst::StdArc> >;
 template class SingleUtteranceNnet3DecoderTpl<fst::ConstGrammarFst >;
 template class SingleUtteranceNnet3DecoderTpl<fst::VectorGrammarFst >;
+template class SingleUtteranceNnet3DecoderTpl<fst::GrammarFst >;
 
 }  // namespace kaldi
diff --git a/src/online2/online-nnet3-decoding.h b/src/online2/online-nnet3-decoding.h
index 9adf77f..3b8f6bc 100644
--- a/src/online2/online-nnet3-decoding.h
+++ b/src/online2/online-nnet3-decoding.h
@@ -98,6 +98,8 @@ class SingleUtteranceNnet3DecoderTpl {
 
   const LatticeFasterOnlineDecoderTpl<FST> &Decoder() const { return decoder_; }
 
+   LatticeFasterOnlineDecoderTpl<FST> *DecoderPtr() { return &decoder_; }
+
   ~SingleUtteranceNnet3DecoderTpl() { }
  private:
 
diff --git a/src/online2/online-timing.h b/src/online2/online-timing.h
index 405294d..c90e371 100644
--- a/src/online2/online-timing.h
+++ b/src/online2/online-timing.h
@@ -87,7 +87,7 @@ class OnlineTimingStats {
 
 class OnlineTimer {
  public:
-  OnlineTimer(const std::string &utterance_id);
+  explicit OnlineTimer(const std::string &utterance_id);
 
   /// The call to SleepUntil(t) will sleep until cur_utterance_length seconds
   /// after this object was initialized, or return immediately if we've
diff --git a/src/rnnlm/rnnlm-core-compute.cc b/src/rnnlm/rnnlm-core-compute.cc
index f0cf448..b7abca8 100644
--- a/src/rnnlm/rnnlm-core-compute.cc
+++ b/src/rnnlm/rnnlm-core-compute.cc
@@ -30,8 +30,8 @@ BaseFloat RnnlmCoreComputer::Compute(
     const RnnlmExample &minibatch,
     const RnnlmExampleDerived &derived,
     const CuMatrixBase<BaseFloat> &word_embedding,
-    BaseFloat *weight,
-    CuMatrixBase<BaseFloat> *word_embedding_deriv) {
+    CuMatrixBase<BaseFloat> *word_embedding_deriv,
+    BaseFloat *weight) {
   using namespace nnet3;
 
   bool need_model_derivative = false;
diff --git a/src/rnnlm/rnnlm-core-compute.h b/src/rnnlm/rnnlm-core-compute.h
index 6012da1..e8415d2 100644
--- a/src/rnnlm/rnnlm-core-compute.h
+++ b/src/rnnlm/rnnlm-core-compute.h
@@ -40,7 +40,7 @@ class RnnlmCoreComputer {
        @param [in] nnet   The neural network that is to be used to evaluate
                           likelihoods (and possibly derivatives).
    */
-  RnnlmCoreComputer(const nnet3::Nnet &nnet);
+  explicit RnnlmCoreComputer(const nnet3::Nnet &nnet);
 
   /* Compute the objective on one minibatch (and possibly also derivatives
      w.r.t. the embedding).
@@ -72,8 +72,8 @@ class RnnlmCoreComputer {
   BaseFloat Compute(const RnnlmExample &minibatch,
                     const RnnlmExampleDerived &derived,
                     const CuMatrixBase<BaseFloat> &word_embedding,
-                    BaseFloat *weight = NULL,
-                    CuMatrixBase<BaseFloat> *word_embedding_deriv = NULL);
+                    CuMatrixBase<BaseFloat> *word_embedding_deriv = NULL,
+                    BaseFloat *weight = NULL);
 
  private:
 
diff --git a/src/rnnlm/sampling-lm-estimate.h b/src/rnnlm/sampling-lm-estimate.h
index 564993f..3502982 100644
--- a/src/rnnlm/sampling-lm-estimate.h
+++ b/src/rnnlm/sampling-lm-estimate.h
@@ -197,7 +197,7 @@ class SamplingLm;  // Forward declaration.
 class SamplingLmEstimator {
  public:
   ///  Constructor.  Retains a reference to 'config'.
-  SamplingLmEstimator(const SamplingLmEstimatorOptions &config);
+  explicit SamplingLmEstimator(const SamplingLmEstimatorOptions &config);
 
   /** Processes one line of the input, adding it to the stored stats.
 
diff --git a/src/rnnlm/sampling-lm.h b/src/rnnlm/sampling-lm.h
index ae7d0a7..54c8483 100644
--- a/src/rnnlm/sampling-lm.h
+++ b/src/rnnlm/sampling-lm.h
@@ -64,7 +64,7 @@ class SamplingLm : public ArpaFileParser {
   // us to avoid having to add a bunch of unnecessary n-grams to satisfy the
   // requirements of the ARPA file format.
   // It assumes that you have already called estimator.Estimate().
-  SamplingLm(const SamplingLmEstimator &estimator);
+  explicit SamplingLm(const SamplingLmEstimator &estimator);
 
   // This constructor is to be used prior to calling the 2-argument
   // Read() that readss the result of calling Write().
diff --git a/src/rnnlmbin/rnnlm-compute-prob.cc b/src/rnnlmbin/rnnlm-compute-prob.cc
index 6110147..e812c3b 100644
--- a/src/rnnlmbin/rnnlm-compute-prob.cc
+++ b/src/rnnlmbin/rnnlm-compute-prob.cc
@@ -107,7 +107,7 @@ int main(int argc, char *argv[]) {
         // compute for this minibatch.
         BaseFloat weight,
             objf = computer.Compute(minibatch, derived, word_embedding_mat,
-                                    &weight, NULL);
+                                    NULL, &weight);
         tot_weight += weight;
         tot_objf += objf;
         num_minibatches++;
diff --git a/src/transform/compressed-transform-stats.h b/src/transform/compressed-transform-stats.h
index 44a0c5a..59a011c 100644
--- a/src/transform/compressed-transform-stats.h
+++ b/src/transform/compressed-transform-stats.h
@@ -44,7 +44,7 @@ namespace kaldi {
 class CompressedAffineXformStats {
  public:
   CompressedAffineXformStats(): beta_(0.0) { }
-  CompressedAffineXformStats(const AffineXformStats &input) {
+  explicit CompressedAffineXformStats(const AffineXformStats &input) {
     CopyFromAffineXformStats(input);
   }
   void CopyFromAffineXformStats(const AffineXformStats &input);
diff --git a/src/transform/fmllr-diag-gmm.h b/src/transform/fmllr-diag-gmm.h
index 54300f9..84b1546 100644
--- a/src/transform/fmllr-diag-gmm.h
+++ b/src/transform/fmllr-diag-gmm.h
@@ -63,11 +63,15 @@ class FmllrDiagGmmAccs: public AffineXformStats {
   // If supplied, the "opts" will only be used to limit the
   // stats that are accumulated, to the parts we'll need in the
   // update.
-  FmllrDiagGmmAccs(const FmllrOptions &opts = FmllrOptions()):
-      opts_(opts) { }
-  explicit FmllrDiagGmmAccs(const FmllrDiagGmmAccs &other):
+  FmllrDiagGmmAccs() { }
+
+  FmllrDiagGmmAccs(const FmllrDiagGmmAccs &other):
       AffineXformStats(other), single_frame_stats_(other.single_frame_stats_),
       opts_(other.opts_) {}
+      
+  // The "opts" will only be used to limit the stats that are accumulated,
+  // to the parts we'll need in the update.
+  explicit FmllrDiagGmmAccs(const FmllrOptions &opts): opts_(opts) { }
   explicit FmllrDiagGmmAccs(int32 dim, const FmllrOptions &opts = FmllrOptions()):
       opts_(opts) { Init(dim); }
   
diff --git a/src/tree/build-tree-questions.h b/src/tree/build-tree-questions.h
index 22f12d6..09003a8 100644
--- a/src/tree/build-tree-questions.h
+++ b/src/tree/build-tree-questions.h
@@ -33,7 +33,7 @@ typedef std::vector<std::pair<EventType, Clusterable*> > BuildTreeStatsType;
 
 /// Typedef used when we get "all keys" from a set of stats-- used in specifying
 /// which kinds of questions to ask.
-typedef enum { kAllKeysInsistIdentical, kAllKeysIntersection, kAllKeysUnion } AllKeysType;
+typedef enum AllKeysType { kAllKeysInsistIdentical, kAllKeysIntersection, kAllKeysUnion } AllKeysType;
 
 /// @}
 
diff --git a/src/tree/context-dep.h b/src/tree/context-dep.h
index 1508616..e9e62cc 100644
--- a/src/tree/context-dep.h
+++ b/src/tree/context-dep.h
@@ -97,6 +97,8 @@ class ContextDependency: public ContextDependencyInterface {
 
   const EventMap &ToPdfMap() const { return *to_pdf_; }
 
+  EventMap *ToPdfMapPtr() const { return to_pdf_; }
+
   /// GetPdfInfo returns a vector indexed by pdf-id, saying for each pdf which
   /// pairs of (phone, pdf-class) it can correspond to.  (Usually just one).
   /// c.f. hmm/hmm-topology.h for meaning of pdf-class.
diff --git a/src/tree/tree-renderer.cc b/src/tree/tree-renderer.cc
index bbaa5cd..81114ed 100644
--- a/src/tree/tree-renderer.cc
+++ b/src/tree/tree-renderer.cc
@@ -197,4 +197,8 @@ void TreeRenderer::Render(const EventType *query = 0) {
   ExpectToken(is_, binary_, "EndContextDependency");
 }
 
+void TreeRenderer::RenderQuery(const EventType &query) {
+  Render(&query);
+}
+
 } // namespace kaldi
diff --git a/src/tree/tree-renderer.h b/src/tree/tree-renderer.h
index 78f4b9a..6777581 100644
--- a/src/tree/tree-renderer.h
+++ b/src/tree/tree-renderer.h
@@ -44,6 +44,10 @@ class TreeRenderer {
   // a distinctly colored trace corresponding to the event.
   void Render(const EventType *query);
 
+  void RenderQuery(const EventType &query);
+
+  void Render() { Render(NULL); } 
+
  private:
   // Looks-up the next token from the stream and invokes
   // the appropriate render method to visualize it
diff --git a/src/util/kaldi-holder.h b/src/util/kaldi-holder.h
index f495f27..2a84587 100644
--- a/src/util/kaldi-holder.h
+++ b/src/util/kaldi-holder.h
@@ -26,6 +26,7 @@
 #include <algorithm>
 #include "util/kaldi-io.h"
 #include "util/text-utils.h"
+#include "util/stl-utils.h"
 #include "matrix/kaldi-vector.h"
 #include "matrix/sparse-matrix.h"
 
@@ -229,7 +230,12 @@ template<int kFeatDim = 13> class SphinxMatrixHolder;
 /// and false if there was an error such as an invalid range.
 /// The generic version of this function just fails; we overload the template
 /// whenever we need it for a specific class.
-template <class T>
+/// Following generic definition excludes Matrix and Vector types.
+template <class T,
+          typename std::enable_if<
+              !is_specialization<T, Matrix>::value>::type* = nullptr,
+          typename std::enable_if<
+              !is_specialization<T, Vector>::value>::type* = nullptr >
 bool ExtractObjectRange(const T &input, const std::string &range, T *output) {
   KALDI_ERR << "Ranges not supported for objects of this type.";
   return false;
diff --git a/src/util/kaldi-io.cc b/src/util/kaldi-io.cc
index 96cd8fa..8f66540 100644
--- a/src/util/kaldi-io.cc
+++ b/src/util/kaldi-io.cc
@@ -704,6 +704,12 @@ std::ostream &Output::Stream() {  // will throw if not open; else returns
   return impl_->Stream();
 }
 
+std::ostream *Output::StreamPtr() {  // will throw if not open; else returns
+  // stream.
+  if (!impl_) KALDI_ERR << "Output::StreamPtr() called but not open.";
+  return &(impl_->Stream());
+}
+
 bool Output::Open(const std::string &wxfn, bool binary, bool header) {
   if (IsOpen()) {
     if (!Close()) {  // Throw here rather than return status, as it's an error
@@ -828,6 +834,10 @@ std::istream &Input::Stream() {
   return impl_->Stream();
 }
 
+std::istream *Input::StreamPtr() {
+  if (!IsOpen()) KALDI_ERR << "Input::StreamPtr(), not open.";
+  return &(impl_->Stream());
+}
 
 template <> void ReadKaldiObject(const std::string &filename,
                                  Matrix<float> *m) {
diff --git a/src/util/kaldi-io.h b/src/util/kaldi-io.h
index c28be8a..eb47565 100644
--- a/src/util/kaldi-io.h
+++ b/src/util/kaldi-io.h
@@ -144,6 +144,8 @@ class Output {
 
   std::ostream &Stream();  // will throw if not open; else returns stream.
 
+  std::ostream *StreamPtr(); // will throw if not open; else returns stream.
+
   // Close closes the stream. Calling Close is never necessary unless you
   // want to avoid exceptions being thrown.  There are times when calling
   // Close will hurt efficiency (basically, when using offsets into files,
@@ -193,7 +195,7 @@ class Input {
   /// Equivalent to calling the default constructor followed by Open(); then, if
   /// binary != NULL, it calls ReadHeader(), putting the output in "binary"; it
   /// throws on error.
-  Input(const std::string &rxfilename, bool *contents_binary = NULL);
+  explicit Input(const std::string &rxfilename, bool *contents_binary = NULL);
 
   Input(): impl_(NULL) {}
 
@@ -226,6 +228,9 @@ class Input {
   // Returns the underlying stream. Throws if !IsOpen()
   std::istream &Stream();
 
+  // Returns the underlying stream. Throws if !IsOpen()
+  std::istream *StreamPtr();
+
   // Destructor does not throw: input streams may legitimately fail so we
   // don't worry about the status when we close them.
   ~Input();
diff --git a/src/util/kaldi-table.h b/src/util/kaldi-table.h
index 6865cea..4d7fa4f 100644
--- a/src/util/kaldi-table.h
+++ b/src/util/kaldi-table.h
@@ -271,6 +271,14 @@ class RandomAccessTableReader {
   RandomAccessTableReader(const RandomAccessTableReader<Holder>
                           &other):
       impl_(NULL) { KALDI_ASSERT(other.impl_ == NULL); }
+
+  // Allow move assignment.
+  RandomAccessTableReader &operator = (RandomAccessTableReader &&other) {
+    this->Close();
+    this->impl_ = other.impl_;
+    other.impl_ = NULL;
+    return *this;
+  }
  private:
   // Disallow assignment.
   RandomAccessTableReader &operator=(const RandomAccessTableReader<Holder>&);
@@ -353,6 +361,14 @@ class SequentialTableReader {
   // stl vector)
   SequentialTableReader(const SequentialTableReader<Holder> &other):
       impl_(NULL) { KALDI_ASSERT(other.impl_ == NULL); }
+
+  // Allow move assignment.
+  SequentialTableReader &operator = (SequentialTableReader &&other) {
+    this->Close();
+    this->impl_ = other.impl_;
+    other.impl_ = NULL;
+    return *this;
+  }
  private:
   // Disallow assignment.
   SequentialTableReader &operator = (const SequentialTableReader<Holder>&);
@@ -406,6 +422,14 @@ class TableWriter {
   TableWriter(const TableWriter &other): impl_(NULL) {
     KALDI_ASSERT(other.impl_ == NULL);
   }
+
+  // Allow move assignment.
+  TableWriter &operator = (TableWriter &&other) {
+    this->Close();
+    this->impl_ = other.impl_;
+    other.impl_ = NULL;
+    return *this;
+  }
  private:
   TableWriter &operator = (const TableWriter&);  // Disallow assignment.
 
@@ -450,6 +474,14 @@ class RandomAccessTableReaderMapped {
   inline bool Close() { return reader_.Close(); }
 
 
+  // Allow move assignment.
+  RandomAccessTableReaderMapped &operator = (
+      RandomAccessTableReaderMapped &&other) {
+    this->Close();
+    this->impl_ = other.impl_;
+    other.impl_ = NULL;
+    return *this;
+  }
 
   // The default copy-constructor will do what we want: it will crash for
   // already-opened readers, by calling the member-variable copy-constructors.
diff --git a/src/util/stl-utils.h b/src/util/stl-utils.h
index 647073a..5a5901f 100644
--- a/src/util/stl-utils.h
+++ b/src/util/stl-utils.h
@@ -312,6 +312,21 @@ inline void MergePairVectorSumming(std::vector<std::pair<I, F> > *vec) {
   vec->erase(out, end);
 }
 
+/// This checks if a given type is a specialization of a reference type.
+/// Useful for excluding a type from the primary template of a function
+/// when an explicit specialization exist for that type. e.g.
+/// template <class T,
+///           class std::enable_if<
+///               !is_specialization<T, Matrix>::value>::type* = nullptr>
+/// bool ExtractObjectRange(const T &input, const string &range, T *output) {
+///   return false;
+/// }
+template<typename Test, template<typename...> class Ref>
+struct is_specialization : std::false_type {};
+
+template<template<typename...> class Ref, typename... Args>
+struct is_specialization<Ref<Args...>, Ref>: std::true_type {};
+
 }  // namespace kaldi
 
 #endif  // KALDI_UTIL_STL_UTILS_H_
-- 
2.38.0

